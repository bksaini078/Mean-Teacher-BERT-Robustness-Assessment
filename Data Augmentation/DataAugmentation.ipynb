{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DataAugmentation.ipynb","provenance":[],"collapsed_sections":["NDf7VCdL2ioc","ChTML2URuycn"],"mount_file_id":"10bl527YKszhgQ0qsD-aJ_4xgidSjDsFI","authorship_tag":"ABX9TyP2pVT+Gkodyk9Ru+Zs5keW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e02f51d256c94d5193a37b8b51645fbe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_272ed058cd3c4b89bbb455e195b8b30b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9535efed15e3412fb2e6e5242124da8c","IPY_MODEL_630d963a77d34867934d5ce1c9999968"]}},"272ed058cd3c4b89bbb455e195b8b30b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9535efed15e3412fb2e6e5242124da8c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_44af3b6475774798b280cdcb881e81fb","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_39a2dec042ef46e7b8e7d8919fcafc77"}},"630d963a77d34867934d5ce1c9999968":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7cfc2cc656a54561a60c5ce8919490e3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:01&lt;00:00, 18.3B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_15dc97ca1fa94f199d7505a02d6cdf27"}},"44af3b6475774798b280cdcb881e81fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"39a2dec042ef46e7b8e7d8919fcafc77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7cfc2cc656a54561a60c5ce8919490e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"15dc97ca1fa94f199d7505a02d6cdf27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fd90066b0ebc4f34ae0472c8ee734d13":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d05fd88c67a346c597c954f2ea1c8839","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_291dc5a3ff2b4fef973d8fcc500e47a9","IPY_MODEL_f6dea4d037774a829e259bbef5c73bc9"]}},"d05fd88c67a346c597c954f2ea1c8839":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"291dc5a3ff2b4fef973d8fcc500e47a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2a2814c6e23d47a88421f07b1b043cff","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7580919a2d0640c1817d1ae6fd1a3832"}},"f6dea4d037774a829e259bbef5c73bc9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fc053b6fe69e4957a22cf3b623cc54b2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:20&lt;00:00, 27.8B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bcf6405d623c4e61bc8978cda10e0869"}},"2a2814c6e23d47a88421f07b1b043cff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7580919a2d0640c1817d1ae6fd1a3832":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fc053b6fe69e4957a22cf3b623cc54b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bcf6405d623c4e61bc8978cda10e0869":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c76217ac04b74fc8b4316840bc06201a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e66f89752ae64e1b81ca25c9c2d1cdc6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_796a465ff1e74a119d7a845630d600c3","IPY_MODEL_10a23e7754874b668e1c1bcfd3b5e48b"]}},"e66f89752ae64e1b81ca25c9c2d1cdc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"796a465ff1e74a119d7a845630d600c3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_27149a9010644fcfa3b2485cb323a13f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b8bf6c13d9d64530879ec3f91898185d"}},"10a23e7754874b668e1c1bcfd3b5e48b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a0d7c725190b48cb9e207797eaa9e0bf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:04&lt;00:00, 54.3kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_65b8eedb8705418b84ec350a8a1e92ae"}},"27149a9010644fcfa3b2485cb323a13f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b8bf6c13d9d64530879ec3f91898185d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a0d7c725190b48cb9e207797eaa9e0bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"65b8eedb8705418b84ec350a8a1e92ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"32b3e6da498449f0bc82a8f20e6e0b7f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0b3b964af22c4fb2bdc902522d0b504b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9fc6a458e3c44b158945d4affdaee805","IPY_MODEL_ad63d396108f461cbc423a0659a2c553"]}},"0b3b964af22c4fb2bdc902522d0b504b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9fc6a458e3c44b158945d4affdaee805":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2bcdd61d659d4317807ad899b655cb74","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_40d42679f85f44cb893833205f006b91"}},"ad63d396108f461cbc423a0659a2c553":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3a6953cd1ce646eea683c7d871bde787","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:02&lt;00:00, 188kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a6a0bf62f7124b51940b282946cb2c75"}},"2bcdd61d659d4317807ad899b655cb74":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"40d42679f85f44cb893833205f006b91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3a6953cd1ce646eea683c7d871bde787":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a6a0bf62f7124b51940b282946cb2c75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"857d64d69c284ac8b75fe059fac600e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cde17f75febe4ad29263c3e989460d9c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_82b141ebb22b42ddadfed392057ff840","IPY_MODEL_28e6695f035c47a991f6bd8b9466cc68"]}},"cde17f75febe4ad29263c3e989460d9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"82b141ebb22b42ddadfed392057ff840":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_286b2e82e7a94cf08a2f7f1aeab119ed","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":536063208,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":536063208,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fd6a3f34653c45b396e31fe4eb007ea4"}},"28e6695f035c47a991f6bd8b9466cc68":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_91ad6352b5c0449b9672a66808388f7e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 536M/536M [00:13&lt;00:00, 40.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_482e1a623f8b422cbeb415b55af0f15c"}},"286b2e82e7a94cf08a2f7f1aeab119ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fd6a3f34653c45b396e31fe4eb007ea4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"91ad6352b5c0449b9672a66808388f7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"482e1a623f8b422cbeb415b55af0f15c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"l662lxLOIu7W"},"source":["# Augmentation \n","This notebook is related to exploration and creation of prominent advesarial unlabelled data. Three main mechanism is implemented:\n","1. Word synonym replacement.\n","2. Word context replacement using langauge models\n","3. BackTranslation\n","\n","Approach:\n","1. Splitting training dataset in three parts, one for word synonym replacement, second for word replacement using langauge models, and the last one for back translation. \n","2. Goal is to generate 3 times more data than training data. so, during training we can adjust the ratio between labeled and unlabeled data. \n","\n","__Date June 27 :__\n","- Implementing changing most important word in case of synonym replacement. \n","- And, after generating the adversarial text we need to check the similarity score between original text and adversarial text then keep only most similar article (using some threshold). And, constraint would be minimum percentage of perturbation(again introducting some threshold).\n","\n","__Date July 1 :__\n","- Implementing the perturbation percentage.Formula would be number of words changed divided by total words.\n","\n","__Date July 3 :__\n","- Changing in the strategy of synonym change and including ranking words as per attack.\n","- Evaluation code for langauge model.\n"]},{"cell_type":"markdown","metadata":{"id":"11o3HinR2grA"},"source":["# Import and Installation"]},{"cell_type":"code","metadata":{"id":"hutwD7UrI17D"},"source":["!pip install nlpaug\n","!pip install transformers\n","!pip install torch\n","!pip install fastBPE sacremoses\n","!pip install hydra-core\n","!pip install omegaconf\n","!pip install sentencepiece==0.1.94\n","!pip install mosestokenizer==1.1.0\n","!pip install semantic-text-similarity\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wJM6u36IJOkH"},"source":["import transformers\n","import nlpaug.augmenter.word as naw\n","import nlpaug.augmenter.sentence as nas\n","import os\n","import pandas as pd \n","import numpy as np \n","from transformers import MarianMTModel, MarianTokenizer\n","import tensorflow as tf\n","\n","from sklearn.metrics import accuracy_score, classification_report"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NDf7VCdL2ioc"},"source":["# Reading Data"]},{"cell_type":"code","metadata":{"id":"UdP5UAJ30_sp"},"source":["os.chdir('/content/drive/MyDrive/Master Thesis/')\n","\n","#global parameter declaration \n","random_state=42\n","feature_col=\"tweet\" # as we only need feature in creating the prominent unlabeld dataset\n","aug_col='aug_tweet'\n","target_col='label'\n","perturb_col= 'Perturbation%'\n","\n","# augmentation parameter \n","max_word_aug=10 # adjust this parameter to change the word level augmentation\n","max_len=100\n","\n","pretrained_weights= 'bert-base-uncased'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UlaRXlLfJsI5"},"source":["# if we want to add augmentation on raw data \n","train_loc= 'codalab/RawData.csv'\n","\n","# incase of preprocess data preprocess data\n","proc_train_loc='codalab/PreprocessedData/pr_train.csv'\n","\n","#test dataset\n","test_loc='codalab/PreprocessedData/pr_test.csv'\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"03P1MvtiLDEn","executionInfo":{"status":"ok","timestamp":1625351027899,"user_tz":-120,"elapsed":2600,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"174ace7a-4ba9-4e12-cbb7-b59a9a455e00"},"source":["#reading dataset\n","adv_unlabel_df= pd.read_csv(proc_train_loc,\n","                           header='infer',\n","                           usecols=[feature_col,target_col]) \n","\n","adv_unlabel_df= adv_unlabel_df.dropna().reset_index(drop=True)\n","adv_unlabel_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>the cdc currently report death in general the ...</td>\n","      <td>real</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>state reported death a small rise from last tu...</td>\n","      <td>real</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>politically correct woman almost u pandemic a ...</td>\n","      <td>fake</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>indiafightscorona we have covid testing labora...</td>\n","      <td>real</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>populous state can generate large case count b...</td>\n","      <td>real</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               tweet label\n","0  the cdc currently report death in general the ...  real\n","1  state reported death a small rise from last tu...  real\n","2  politically correct woman almost u pandemic a ...  fake\n","3  indiafightscorona we have covid testing labora...  real\n","4  populous state can generate large case count b...  real"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xsrbJX6dImE4","executionInfo":{"status":"ok","timestamp":1625351029167,"user_tz":-120,"elapsed":1288,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"6a6bafdc-a222-43c1-fe20-7f6986331c6c"},"source":["# adversarial test data \n","adv_test_df= pd.read_csv(test_loc,header='infer',index_col=[0])\n","adv_test_df= adv_test_df.dropna().reset_index(drop=True)\n","adv_test_df.head(), adv_test_df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(                                               tweet label\n"," 0  our daily update is published state reported 7...  real\n"," 1                 alfalfa is the only cure for covid  fake\n"," 2  president trump asked what he would do if he w...  fake\n"," 3  state reported death we are still seeing a sol...  real\n"," 4  this is the sixth time a global health emergen...  real, (2042, 2))"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"ChTML2URuycn"},"source":["# Function declaration"]},{"cell_type":"code","metadata":{"id":"pO99gEoV-26I"},"source":["#splitting the dataset \n","def df_splitter(df,num_of_partition=3):\n","    '''Function to split the dataframe into num_of_partition\n","     portion via sampling technique,and return three dataframe, \n","     in zip format RETURN: Collection of Dataframe'''\n","\n","    partition_ratio= 1/num_of_partition\n","    collection=[]\n","\n","    for i in range(num_of_partition):\n","        # this need to perform to get random sample from if we are using df.sample.\n","        random_state= np.random.choice(np.random\n","                                       .randint(1,100))\n","\n","        collection.append(df.sample(frac=partition_ratio,\n","                                    replace=True,\n","                                    random_state=random_state)\n","                                    .reset_index(drop=True))\n","\n","    return collection\n","\n","# Synonyn Augmentation\n","def synonym_augment(df,max_aug=10,aug_src='wordnet', iter=2):\n","    '''Synonym Based Augmentation: To augment data \n","    with max_aug synonym in the given articles, \n","    we can change aug_src ['ppdb']\n","    RETURN: Dataframe'''\n","    print('Executing synonym augmentation')\n","    df_aug=pd.DataFrame()\n","    aug=naw.SynonymAug(aug_src=aug_src,\n","                       aug_max=max_aug)\n","    try:\n","        for i in range(iter):\n","            df[aug_col]= aug.augment(list(df[feature_col].values))\n","            df_aug=df_aug.append(df)   \n","    except e:\n","        print(e)\n","        pass\n","\n","    return df_aug.reset_index(drop=True)\n","\n","#Context Augmentation\n","def context_augment(df,pretrained_model='distilbert-base-uncased',action='substitute',iter=2):\n","    '''Context Based Augmentation: To augment data using langauge model \n","    the given articles, we can change pretrained_model to different language model.\n","    RETURN: Dataframe'''\n","\n","    #this need to perform as above 512 can crash the system.\n","    print('Executing context augmentation')\n","    df=df[(df[feature_col].str.len()<100)&(df[feature_col].str.len()>10)]\n","    #augmentor\n","    try:\n","        aug=naw.ContextualWordEmbsAug(model_path=pretrained_model,\n","                                    action=action)\n","        \n","        df_aug=pd.DataFrame()\n","        for i in range(iter):\n","            df[aug_col]= aug.augment(list(df[feature_col].values))\n","            df_aug=df_aug.append(df)\n","    except Exception as e:\n","        print(e)\n","        pass\n","\n","    return df_aug.reset_index(drop=True)\n","\n","#Back-translation Augmentation\n","def back_translation(df):\n","    '''Function to create dataframe using backtranslation\n","     technique usign Marian tokenizer. RETURN: Dataframe'''\n","    \n","    print('Executing Backtranslation augmentation')\n","\n","    # english to romance\n","    target_model_name = 'Helsinki-NLP/opus-mt-en-ROMANCE'\n","    tokenizer = MarianTokenizer.from_pretrained(target_model_name)\n","    model = MarianMTModel.from_pretrained(target_model_name)\n","    \n","    #romance to english\n","    en_model_name = 'Helsinki-NLP/opus-mt-ROMANCE-en'\n","    en_tokenizer = MarianTokenizer.from_pretrained(en_model_name)\n","    en_model = MarianMTModel.from_pretrained(en_model_name)\n","    \n","    def translated_texts(text):\n","        translated = model.generate(**tokenizer([text], return_tensors=\"pt\", padding=True))\n","        rom_texts = tokenizer.decode(translated[0], skip_special_tokens=True) \n","\n","        back_translated = en_model.generate(**en_tokenizer(rom_texts, return_tensors=\"pt\", padding=True))\n","        translated_texts = en_tokenizer.decode(back_translated[0], skip_special_tokens=True).lower()\n","\n","        return translated_texts\n","\n","    #taking less than 200 length\n","    df_back_translation= df[(df['tweet'].str.len()<100) & (df['tweet'].str.len()>15)].reset_index(drop=True)\n","    df_back_translation[aug_col]=df_back_translation[feature_col].apply(lambda row: translated_texts(row))\n","\n","    return df_back_translation\n","\n","\n","def data_cleaning(df):\n","    '''\n","    This function will check and remove rows which has :\n","    - Augmented tweet and original text are same \n","    - if length of the augmented text(unique words count ) is less than 3\n","    '''\n","    print(f'Initial Length of the dataframe: {len(df)}')\n","    print(f'Number of same augmented text  and original text:{len(df)-len(df[~(df[feature_col]==df[aug_col])])}')\n","    df=df[~(df[feature_col]==df[aug_col])].reset_index(drop=True)\n","    print(f'After removinal : {len(df)}')\n","\n","    # unique words replacement\n","    df['set_aug']= df[aug_col].apply(lambda row: len(set(row.split(' '))))\n","    df=df[~(df['set_aug']<3)].reset_index(drop=True)\n","    print(f'Length after dropping less than 3 unique words in the augtweet: {len(df)}')\n","    \n","\n","    return df[df.columns.difference(['set_aug'])]\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZbdpkbUNjHPb"},"source":["# Data Augmentation"]},{"cell_type":"code","metadata":{"id":"LtwzhAOSetA5","colab":{"base_uri":"https://localhost:8080/","height":732},"executionInfo":{"status":"error","timestamp":1625299204459,"user_tz":-120,"elapsed":738,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"7c1cf208-b7b2-474d-c767-06441640ad4b"},"source":["\n","df_syn,df_context,df_back_translated=df_splitter(adv_unlabel_df)\n","\n","#Creating Unlabel data \n","with tf.device('/device:GPU:0'):\n","    df_syn= synonym_augment(df_syn,max_aug=10)\n","    df_syn= data_cleaning(df_syn)\n","    df_syn.to_csv('codalab/AugmentedData/aug_synonym.csv', index=False)\n","\n","    df_context= context_augment(df_context)\n","    df_context=data_cleaning(df_context)\n","    df_context.to_csv('codalab/AugmentedData/aug_context.csv', index=False)\n","\n","    df_back_translated= back_translation(df_back_translated)\n","    df_back_translated=data_cleaning(df_back_translated)\n","    df_back_translated.to_csv('codalab/AugmentedData/aug_backtranslated.csv', index=False)\n","\n","\n","# Adversarial test data \n","'''Here I am creating three different adversarial dataset, to observe the effects of different attacks'''\n","print('Executing test data')\n","with tf.device('/device:GPU:0'):\n","    # keeping max aug less in order to prevent it from lossing semantics\n","    adv_test_syn_df=synonym_augment(adv_test_df,max_aug=10,iter=1) \n","    adv_test_syn_df= data_cleaning(adv_test_syn_df)\n","    adv_test_syn_df.to_csv('codalab/AugmentedData/adv_test_syn.csv', index=False)\n","\n","    adv_test_context_df=context_augment(adv_test_df,iter=1) # keeping max aug less in order to prevent it from lossing \n","    adv_test_context_df= data_cleaning(adv_test_context_df)\n","    adv_test_context_df.to_csv('codalab/AugmentedData/adv_test_context.csv', index=False)\n","\n","    adv_test_backTrans_df= back_translation(adv_test_df)\n","    adv_test_backTrans_df= data_cleaning(adv_test_backTrans_df)\n","    adv_test_backTrans_df.to_csv('codalab/AugmentedData/adv_test_backTrans.csv', index=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Executing synonym augmentation\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-dfdd39d9beb3>\u001b[0m in \u001b[0;36msynonym_augment\u001b[0;34m(df, max_aug, aug_src, iter)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maug_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mdf_aug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_aug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nlpaug/base_augmenter.py\u001b[0m in \u001b[0;36maugment\u001b[0;34m(self, data, n, num_thread)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnum_thread\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                     \u001b[0maugmented_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maction_fx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nlpaug/base_augmenter.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnum_thread\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                     \u001b[0maugmented_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maction_fx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nlpaug/augmenter/word/synonym.py\u001b[0m in \u001b[0;36msubstitute\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nlpaug/model/word_dict/wordnet.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(cls, tokens)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \"\"\"\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mAP_MODEL_LOC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'file:'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'taggers/averaged_perceptron_tagger/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mPICKLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-28ab2995bae6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Creating Unlabel data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf_syn\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msynonym_augment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_syn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_aug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdf_syn\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdata_cleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_syn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf_syn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'codalab/AugmentedData/aug_synonym.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-dfdd39d9beb3>\u001b[0m in \u001b[0;36msynonym_augment\u001b[0;34m(df, max_aug, aug_src, iter)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maug_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mdf_aug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_aug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'e' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"dYEIERamh1jj"},"source":["# Similarty Exploration"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"aAarqWa4h6Os","executionInfo":{"status":"ok","timestamp":1625351030951,"user_tz":-120,"elapsed":1788,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"358ff275-2880-4d02-eed2-dc48fc19a913"},"source":["os.chdir('/content/drive/MyDrive/Master Thesis/')\n","\n","#reading the augmented test data for exploration\n","adv_test_syn_df= pd.read_csv('codalab/AugmentedData/adv_test_syn.csv')\n","adv_test_context_df= pd.read_csv('codalab/AugmentedData/adv_test_context.csv')\n","adv_test_backTrans_df= pd.read_csv('codalab/AugmentedData/adv_test_backTrans.csv')\n","adv_test_syn_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>aug_tweet</th>\n","      <th>label</th>\n","      <th>tweet</th>\n","      <th>CosineSim</th>\n","      <th>Wmd</th>\n","      <th>Semantic_sim</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>our daily update is published state reported 7...</td>\n","      <td>real</td>\n","      <td>our daily update is published state reported 7...</td>\n","      <td>0.853411</td>\n","      <td>0.186420</td>\n","      <td>4.611340</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>alfalfa is the alone cure for covid</td>\n","      <td>fake</td>\n","      <td>alfalfa is the only cure for covid</td>\n","      <td>0.752320</td>\n","      <td>0.140226</td>\n","      <td>4.618185</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>president trump ask what he would do if he be ...</td>\n","      <td>fake</td>\n","      <td>president trump asked what he would do if he w...</td>\n","      <td>0.820021</td>\n","      <td>0.147841</td>\n","      <td>4.717221</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>state reported death we follow still seeing a ...</td>\n","      <td>real</td>\n","      <td>state reported death we are still seeing a sol...</td>\n","      <td>0.759327</td>\n","      <td>0.160945</td>\n","      <td>4.360808</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>this is the sixth fourth dimension a global we...</td>\n","      <td>real</td>\n","      <td>this is the sixth time a global health emergen...</td>\n","      <td>0.713065</td>\n","      <td>0.295865</td>\n","      <td>4.121512</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           aug_tweet  ... Semantic_sim\n","0  our daily update is published state reported 7...  ...     4.611340\n","1                alfalfa is the alone cure for covid  ...     4.618185\n","2  president trump ask what he would do if he be ...  ...     4.717221\n","3  state reported death we follow still seeing a ...  ...     4.360808\n","4  this is the sixth fourth dimension a global we...  ...     4.121512\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":422},"id":"FKgBUGTeqduq","executionInfo":{"status":"ok","timestamp":1625104307557,"user_tz":-120,"elapsed":224,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"8548844b-023c-4959-f461-d20f942e41b0"},"source":["def perturb_cal(row):\n","  '''\n","  This function calculate perturbation percentage \n","  in the augmented text w.r.t original text.\n","  Formula is counting word difference/length of original text\n","  '''\n","  list1=row[feature_col].split()\n","  list2=row[aug_col].split()\n","  count=0\n","  for w1,w2 in zip(list1,list2):\n","    if w1!=w2:\n","      count+=1\n","  perturb_per= round((count/len(list1))*100,3)\n","  return perturb_per\n","\n","adv_test_syn_df[perturb_col]=adv_test_syn_df.apply(lambda row: perturb_cal(row),axis=1)\n","adv_test_syn_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>aug_tweet</th>\n","      <th>label</th>\n","      <th>tweet</th>\n","      <th>CosineSim</th>\n","      <th>Wmd</th>\n","      <th>Semantic_sim</th>\n","      <th>Perturbation%</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>our daily update is published state reported 7...</td>\n","      <td>real</td>\n","      <td>our daily update is published state reported 7...</td>\n","      <td>0.853411</td>\n","      <td>0.186420</td>\n","      <td>4.611340</td>\n","      <td>8.000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>alfalfa is the alone cure for covid</td>\n","      <td>fake</td>\n","      <td>alfalfa is the only cure for covid</td>\n","      <td>0.752320</td>\n","      <td>0.140226</td>\n","      <td>4.618185</td>\n","      <td>14.286</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>president trump ask what he would do if he be ...</td>\n","      <td>fake</td>\n","      <td>president trump asked what he would do if he w...</td>\n","      <td>0.820021</td>\n","      <td>0.147841</td>\n","      <td>4.717221</td>\n","      <td>12.500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>state reported death we follow still seeing a ...</td>\n","      <td>real</td>\n","      <td>state reported death we are still seeing a sol...</td>\n","      <td>0.759327</td>\n","      <td>0.160945</td>\n","      <td>4.360808</td>\n","      <td>66.667</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>this is the sixth fourth dimension a global we...</td>\n","      <td>real</td>\n","      <td>this is the sixth time a global health emergen...</td>\n","      <td>0.713065</td>\n","      <td>0.295865</td>\n","      <td>4.121512</td>\n","      <td>84.000</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1978</th>\n","      <td>a major fear be that specificity be not test u...</td>\n","      <td>real</td>\n","      <td>a major concern is that specificity is not tes...</td>\n","      <td>0.559163</td>\n","      <td>0.291761</td>\n","      <td>4.164474</td>\n","      <td>51.724</td>\n","    </tr>\n","    <tr>\n","      <th>1979</th>\n","      <td>rt whoafro the covid virus hasnt been found to...</td>\n","      <td>real</td>\n","      <td>rt whoafro the covid virus hasnt been found to...</td>\n","      <td>0.907733</td>\n","      <td>0.206634</td>\n","      <td>4.570009</td>\n","      <td>40.909</td>\n","    </tr>\n","    <tr>\n","      <th>1980</th>\n","      <td>tonight midnight onwards catastrophe managemen...</td>\n","      <td>fake</td>\n","      <td>tonight midnight onwards disaster management a...</td>\n","      <td>0.825504</td>\n","      <td>0.110223</td>\n","      <td>4.597428</td>\n","      <td>39.024</td>\n","    </tr>\n","    <tr>\n","      <th>1981</th>\n","      <td>new casing of covid 19nigeria plateau enugu oy...</td>\n","      <td>real</td>\n","      <td>new case of covid 19nigeria plateau enugu oyo ...</td>\n","      <td>0.795133</td>\n","      <td>0.200797</td>\n","      <td>3.802569</td>\n","      <td>11.538</td>\n","    </tr>\n","    <tr>\n","      <th>1982</th>\n","      <td>more than than half of pregnant woman recently...</td>\n","      <td>real</td>\n","      <td>more than half of pregnant woman recently admi...</td>\n","      <td>0.851115</td>\n","      <td>0.111750</td>\n","      <td>4.574050</td>\n","      <td>92.308</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1983 rows × 7 columns</p>\n","</div>"],"text/plain":["                                              aug_tweet  ... Perturbation%\n","0     our daily update is published state reported 7...  ...         8.000\n","1                   alfalfa is the alone cure for covid  ...        14.286\n","2     president trump ask what he would do if he be ...  ...        12.500\n","3     state reported death we follow still seeing a ...  ...        66.667\n","4     this is the sixth fourth dimension a global we...  ...        84.000\n","...                                                 ...  ...           ...\n","1978  a major fear be that specificity be not test u...  ...        51.724\n","1979  rt whoafro the covid virus hasnt been found to...  ...        40.909\n","1980  tonight midnight onwards catastrophe managemen...  ...        39.024\n","1981  new casing of covid 19nigeria plateau enugu oy...  ...        11.538\n","1982  more than than half of pregnant woman recently...  ...        92.308\n","\n","[1983 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"jUN98OJGh6GB"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","import gensim.downloader as api\n","from semantic_text_similarity.models import WebBertSimilarity\n","from semantic_text_similarity.models import ClinicalBertSimilarity\n","\n","wmd_model = api.load('word2vec-google-news-300')\n","vectorizer = TfidfVectorizer()\n","web_model = WebBertSimilarity(device='cpu', batch_size=10)\n","\n","def wmd(text1,text2):\n","  '''\n","  Function to calculate the word moving distance between two text statements.\n","  0- means same sentence \n","  >0- some differences in the sentences\n","  '''\n","  return  wmd_model.wmdistance(text1, text2)\n","\n","def cosine_sim(text1, text2):\n","  '''\n","  Function to calculate the cosine similarity between two statements.\n","  0- NO similarity\n","  1- Same sentence\n","  '''\n","  tfidf = vectorizer.fit_transform([text1, text2])\n","  return ((tfidf * tfidf.T).A)[0,1]\n","\n","def semantic_sim(text1,text2):\n","  '''\n","  Function to calculate the sematic similarity between texts \n","  0- No similarity\n","  5- Same sentence\n","  '''\n","  return web_model.predict([(text1,text2)])[0]\n","  \n","def similarity_exploration(df):\n","  '''\n","  Adding similarity column in the dataframe.\n","  '''\n","  df['CosineSim']= df.apply(lambda row: cosine_sim(row[aug_col],row[feature_col]),axis=1)\n","  df['Wmd']= df.apply(lambda row: wmd(row[aug_col],row[feature_col]),axis=1)\n","  df['Semantic_sim']= df.apply(lambda row: semantic_sim(row[aug_col],row[feature_col]),axis=1)\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WMzC0u1rh59c"},"source":["adv_test_syn_df= similarity_exploration(adv_test_syn_df)\n","\n","adv_test_context_df=similarity_exploration(adv_test_context_df)\n","\n","adv_test_backTrans_df=similarity_exploration(adv_test_backTrans_df)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y8MseO-SvcRb"},"source":["## Saving the files\n"]},{"cell_type":"code","metadata":{"id":"uTmVHCl67ODi","colab":{"base_uri":"https://localhost:8080/","height":422},"executionInfo":{"status":"ok","timestamp":1624867049398,"user_tz":-120,"elapsed":209,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"fdd6de47-5716-43cd-aeaf-fd74fed50c98"},"source":["adv_test_syn_df.to_csv('codalab/AugmentedData/adv_test_syn.csv', index=False)\n","adv_test_context_df.to_csv('codalab/AugmentedData/adv_test_context.csv', index=False)\n","adv_test_backTrans_df.to_csv('codalab/AugmentedData/adv_test_backTrans.csv', index=False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>aug_tweet</th>\n","      <th>label</th>\n","      <th>tweet</th>\n","      <th>CosineSim</th>\n","      <th>Wmd</th>\n","      <th>Semantic_sim</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>president trump asked what he would do if he c...</td>\n","      <td>fake</td>\n","      <td>president trump asked what he would do if he w...</td>\n","      <td>0.815061</td>\n","      <td>0.181594</td>\n","      <td>4.665123</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>an independent predictor of worse prognosis in...</td>\n","      <td>real</td>\n","      <td>low vitamind wa an independent predictor of wo...</td>\n","      <td>0.729728</td>\n","      <td>0.366763</td>\n","      <td>3.140324</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>to say that the law of aid coronavirus of reli...</td>\n","      <td>fake</td>\n","      <td>say the coronavirus aid relief and economic se...</td>\n","      <td>0.628013</td>\n","      <td>0.373009</td>\n","      <td>4.312288</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>a child reaches this stage of fucking blockage</td>\n","      <td>fake</td>\n","      <td>kid reach f k this shit stage of lockdown</td>\n","      <td>0.275196</td>\n","      <td>0.706068</td>\n","      <td>1.935341</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>icu are totally forcing covidant patient to wa...</td>\n","      <td>real</td>\n","      <td>icu are full forcing covid patient to wait hou...</td>\n","      <td>0.615521</td>\n","      <td>0.205245</td>\n","      <td>4.461790</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>590</th>\n","      <td>hot water steam inhalation steam kill home vir...</td>\n","      <td>fake</td>\n","      <td>inhaling hot water steam kill corona virus hom...</td>\n","      <td>0.486416</td>\n","      <td>0.263234</td>\n","      <td>3.856449</td>\n","    </tr>\n","    <tr>\n","      <th>591</th>\n","      <td>total death achieved state reported death date...</td>\n","      <td>real</td>\n","      <td>total death reached state reported covid death...</td>\n","      <td>0.580373</td>\n","      <td>0.246589</td>\n","      <td>3.278967</td>\n","    </tr>\n","    <tr>\n","      <th>592</th>\n","      <td>our number of coves are better than most of th...</td>\n","      <td>fake</td>\n","      <td>our covid number are better than almost all co...</td>\n","      <td>0.390186</td>\n","      <td>0.453013</td>\n","      <td>3.065197</td>\n","    </tr>\n","    <tr>\n","      <th>593</th>\n","      <td>the asymptomatic propagation coronavirus coron...</td>\n","      <td>real</td>\n","      <td>asymptomatic coronavirus spread is rare who say</td>\n","      <td>0.324932</td>\n","      <td>0.431581</td>\n","      <td>4.695443</td>\n","    </tr>\n","    <tr>\n","      <th>594</th>\n","      <td>this paradigm shift paradigm paradigm paradigm...</td>\n","      <td>real</td>\n","      <td>this paradigm shift shine a lighton how behind...</td>\n","      <td>0.220389</td>\n","      <td>1.865592</td>\n","      <td>1.930061</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>595 rows × 6 columns</p>\n","</div>"],"text/plain":["                                             aug_tweet  ... Semantic_sim\n","0    president trump asked what he would do if he c...  ...     4.665123\n","1    an independent predictor of worse prognosis in...  ...     3.140324\n","2    to say that the law of aid coronavirus of reli...  ...     4.312288\n","3       a child reaches this stage of fucking blockage  ...     1.935341\n","4    icu are totally forcing covidant patient to wa...  ...     4.461790\n","..                                                 ...  ...          ...\n","590  hot water steam inhalation steam kill home vir...  ...     3.856449\n","591  total death achieved state reported death date...  ...     3.278967\n","592  our number of coves are better than most of th...  ...     3.065197\n","593  the asymptomatic propagation coronavirus coron...  ...     4.695443\n","594  this paradigm shift paradigm paradigm paradigm...  ...     1.930061\n","\n","[595 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"_M1yd7sz2HbB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gT3mI-03_80R"},"source":["# Evaluation of the model "]},{"cell_type":"code","metadata":{"id":"kmzJWw4HkYxe"},"source":["from transformers import AutoTokenizer, TFAutoModel, TFDistilBertModel, TFBertModel\n","from tensorflow.keras.utils import to_categorical\n","import tensorflow as tf \n","from tensorflow.keras.layers import LSTM, Bidirectional,Dropout, Dense, Embedding, Input \n","from tensorflow.keras.optimizers import Adam \n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.losses import BinaryCrossentropy\n","from tensorflow.keras.metrics import Accuracy\n","from tensorflow.keras.utils import to_categorical\n","\n","max_len= 100\n","learning_rate= 2e-5 \n","\n","def bert_model(max_len,pretrained_weights):\n","    '''BERT model creation with pretrained weights\n","    max_len: input length '''\n","    bert=TFAutoModel.from_pretrained(pretrained_weights)\n","    for layer in bert.layers:\n","        layer.trainable = True\n","    # parameter declaration\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    # declaring inputs, BERT take input_ids and attention_mask as input\n","    input_ids= Input(shape=(max_len,),dtype=tf.int32,name='input_ids')\n","    attention_mask=Input(shape=(max_len,),dtype=tf.int32,name='attention_mask')\n","    bert= bert(input_ids,attention_mask=attention_mask)\n","    x= bert[0][:,0,:]\n","    x=tf.keras.layers.Dropout(0.2)(x)\n","    x= tf.keras.layers.Dense(64)(x)\n","    x=tf.keras.layers.Dense(32)(x)\n","    output=tf.keras.layers.Dense(2,activation='sigmoid')(x)\n","    model=Model(inputs=[input_ids,attention_mask],outputs=[output])\n","    # compiling model \n","    model.compile(optimizer=optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","def label_to_int(row):\n","    if row=='real':\n","        return 0\n","    else:\n","        return 1\n","# Converting to categories \n","def convert_to_category(target, n_classes=2):\n","    return [to_categorical(target,n_classes)]\n","    \n","#creating the tokenizer\n","def create_tokenizer(pretrained_weights='distilbert-base-uncased'):\n","    '''Function to create the tokenizer'''\n","    # print(pretrained_weights)\n","    tokenizer = AutoTokenizer.from_pretrained(pretrained_weights)\n","    return tokenizer\n","\n","\n","\n","# sentence tokenization\n","def sent_tokenization(sentence,pretrained_weights,max_len):\n","    '''dataset: Pandas dataframe with feature name is column name \n","    Pretrained_weights: selected model \n","    RETURN: [input_ids, attention_mask]'''\n","    tokenizer=create_tokenizer(pretrained_weights)\n","    tokens=tokenizer(sentence,return_tensors='tf', \n","              truncation=True,\n","              padding='max_length',\n","              max_length=max_len, \n","              add_special_tokens=True)\n","    return [tokens.input_ids,tokens.attention_mask]\n","\n","def evaluation(model,x_test,y_test):\n","    '''\n","    Evaluation of the model in case you have test data in numpy array format\n","    Return- predicted label and accuracy\n","    '''\n","    y_pred= model.predict(x_test)\n","    confidence=np.around((y_pred *100),decimals=3)\n","    if y_pred.shape[1]>1:\n","        y_pred=tf.argmax(y_pred,1)\n","        y_true=tf.argmax(y_test,1)\n","    else:\n","        y_true=y_test\n","    cl_r=classification_report(y_true,y_pred,output_dict=True)\n","    # print(classification_report(y_true,y_pred))\n","    return confidence,y_pred,y_true,cl_r['accuracy']\n","    \n","def pred_pipeline(model,sentence,label):\n","  # tokenization \n","  x_sent= sent_tokenization(sentence,pretrained_weights,max_len)\n","  # evaluation\n","  conf,pred,true,acc= evaluation(model,x_sent,label)\n","  if true==1:\n","    print('Original-->Fake')\n","  else:\n","    print('Original-->Real')\n","  if pred==1:\n","    print('Predicted-->Fake')\n","  else:\n","    print('Predicted-->Real')\n","\n","  # print('Accuracy:', acc)\n","  return conf,true.numpy()[0],pred.numpy()[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nj0tgyMR9RfH","colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"status":"ok","timestamp":1625351057819,"user_tz":-120,"elapsed":9,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"ac7d00da-98b5-4582-d6f1-9c2d5c410d44"},"source":["aug_test_df=adv_test_df[(adv_test_df[feature_col].str.len()>=10) & (adv_test_df[feature_col].str.len()<=100)][:100].reset_index(drop=True)\n","aug_test_df[target_col]=aug_test_df[target_col].apply(lambda row: label_to_int(row) ).astype(int)\n","aug_test_df[target_col].hist()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f84612e3110>"]},"metadata":{"tags":[]},"execution_count":9},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":213,"referenced_widgets":["e02f51d256c94d5193a37b8b51645fbe","272ed058cd3c4b89bbb455e195b8b30b","9535efed15e3412fb2e6e5242124da8c","630d963a77d34867934d5ce1c9999968","44af3b6475774798b280cdcb881e81fb","39a2dec042ef46e7b8e7d8919fcafc77","7cfc2cc656a54561a60c5ce8919490e3","15dc97ca1fa94f199d7505a02d6cdf27","fd90066b0ebc4f34ae0472c8ee734d13","d05fd88c67a346c597c954f2ea1c8839","291dc5a3ff2b4fef973d8fcc500e47a9","f6dea4d037774a829e259bbef5c73bc9","2a2814c6e23d47a88421f07b1b043cff","7580919a2d0640c1817d1ae6fd1a3832","fc053b6fe69e4957a22cf3b623cc54b2","bcf6405d623c4e61bc8978cda10e0869","c76217ac04b74fc8b4316840bc06201a","e66f89752ae64e1b81ca25c9c2d1cdc6","796a465ff1e74a119d7a845630d600c3","10a23e7754874b668e1c1bcfd3b5e48b","27149a9010644fcfa3b2485cb323a13f","b8bf6c13d9d64530879ec3f91898185d","a0d7c725190b48cb9e207797eaa9e0bf","65b8eedb8705418b84ec350a8a1e92ae","32b3e6da498449f0bc82a8f20e6e0b7f","0b3b964af22c4fb2bdc902522d0b504b","9fc6a458e3c44b158945d4affdaee805","ad63d396108f461cbc423a0659a2c553","2bcdd61d659d4317807ad899b655cb74","40d42679f85f44cb893833205f006b91","3a6953cd1ce646eea683c7d871bde787","a6a0bf62f7124b51940b282946cb2c75"]},"id":"2VMhmd5cu5ye","executionInfo":{"status":"ok","timestamp":1625351069989,"user_tz":-120,"elapsed":9078,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"442c5483-36fb-4569-d47e-e8d7a10014cb"},"source":["tokenizer=create_tokenizer(pretrained_weights)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e02f51d256c94d5193a37b8b51645fbe","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd90066b0ebc4f34ae0472c8ee734d13","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c76217ac04b74fc8b4316840bc06201a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"32b3e6da498449f0bc82a8f20e6e0b7f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":494,"referenced_widgets":["857d64d69c284ac8b75fe059fac600e0","cde17f75febe4ad29263c3e989460d9c","82b141ebb22b42ddadfed392057ff840","28e6695f035c47a991f6bd8b9466cc68","286b2e82e7a94cf08a2f7f1aeab119ed","fd6a3f34653c45b396e31fe4eb007ea4","91ad6352b5c0449b9672a66808388f7e","482e1a623f8b422cbeb415b55af0f15c"]},"id":"2Axkp1U9iMHs","executionInfo":{"status":"ok","timestamp":1625351130962,"user_tz":-120,"elapsed":60992,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"21fae0c0-abc1-4212-ef8f-035a15f82343"},"source":["# what is the performance of this data with the model\n","BERT_model= bert_model(max_len,pretrained_weights) \n","BERT_model.load_weights('SavedModels/BERT_model.h5')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"857d64d69c284ac8b75fe059fac600e0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f851cd4bde0>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f851cd4bde0>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f85385f6dd0> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function wrap at 0x7f85385f6dd0> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lP7_lGnGno8f"},"source":["aug_test_df[target_col]= aug_test_df[target_col].apply(lambda row: convert_to_category(row))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xjC43KXr4MNQ"},"source":["pred_pipeline(BERT_model,aug_test_df[feature_col][0],aug_test_df[target_col][0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IBtcp-N64Ubq"},"source":["result=[]\n","for i in range(1,len(aug_test_df)):\n","  result.append(pred_pipeline(BERT_model,aug_test_df.loc[i,feature_col],aug_test_df.loc[i,target_col]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqWY5Lqm42BP"},"source":["result= np.array(result)\n","result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ARmYbhNiHDET","executionInfo":{"status":"ok","timestamp":1625300231944,"user_tz":-120,"elapsed":207,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"68f396f4-a686-4c43-f160-22fc90f7ffb9"},"source":["# accuracy calculation\n","np.count_nonzero((result[:,1]==result[:,2]).astype(int))/len(result)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9393939393939394"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U1oKspQG8VSH","executionInfo":{"status":"ok","timestamp":1625351169328,"user_tz":-120,"elapsed":342,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"a854ef79-78d5-430b-a1b1-ca14b25c994c"},"source":["sf,lf=aug_test_df[feature_col][0],aug_test_df[target_col][0]\n","sf,lf"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('alfalfa is the only cure for covid', [array([0., 1.], dtype=float32)])"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9Zbicz4J3i5","executionInfo":{"status":"ok","timestamp":1625351172311,"user_tz":-120,"elapsed":353,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"8c1e8165-1e38-4d9b-b5f0-0575b8d176ae"},"source":["s1=aug_test_df[feature_col][1]\n","l1=aug_test_df[target_col][1]\n","s1,l1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('president trump asked what he would do if he were to catch the coronavirus donaldtrump coronavirus',\n"," [array([0., 1.], dtype=float32)])"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"CC86VLJdcSyf"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-OMX_tohKHy_","executionInfo":{"status":"ok","timestamp":1625351189948,"user_tz":-120,"elapsed":6214,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"eb732c9c-917f-4232-c371-018ef758b62c"},"source":["pred_pipeline(BERT_model,sf,lf)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original-->Fake\n","Predicted-->Fake\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(array([[ 0, 99]]), 1, 1)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LUIvwSJ4LsVr","executionInfo":{"status":"ok","timestamp":1625351197408,"user_tz":-120,"elapsed":979,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"6cf388a7-9ca9-4caa-db11-24faf14939bc"},"source":["from nltk.corpus import wordnet \n","import nltk\n","nltk.download('wordnet')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lF8WTe63XNdf","executionInfo":{"status":"ok","timestamp":1625283047452,"user_tz":-120,"elapsed":213,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"50ac557d-7c8b-4222-f1fc-3c926af52717"},"source":["import nltk\n","nltk.download('averaged_perceptron_tagger')\n","def synonym_sent_augment(sent,max_aug=20,aug_src='wordnet', iter=20):\n","    '''Synonym Based Augmentation: To augment data \n","    with max_aug synonym in the given articles, \n","    we can change aug_src ['ppdb']\n","    RETURN: Dataframe'''\n","    aug=naw.SynonymAug(aug_src=aug_src,\n","                       aug_max=max_aug)\n","    aug_sent=[]\n","    try:\n","        for i in range(iter):\n","            aug_sent.append(aug.augment(sent))\n","    except Exception as e:\n","        print(e)\n","        pass\n","\n","    return aug_sent\n","aug_s_list=synonym_sent_augment(sf)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CtfB1By0ZFmL"},"source":["prominent_aug=[]\n","aug_s_list=sf.split()\n","for item in aug_s_list:\n","  print(item)\n","  conf,true,pred= pred_pipeline(BERT_model,item,lf)\n","  print(conf)\n","  if true!=pred:\n","    prominent_aug.append(item)\n","prominent_aug\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w6dkonIPKcHX","executionInfo":{"status":"ok","timestamp":1625351613427,"user_tz":-120,"elapsed":22584,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"83979693-9c43-44af-c7e1-8f63d8204f6a"},"source":["tok=sf.split(' ')\n","imp_word=[]\n","print('sentence:', sf)\n","for i,item in enumerate(tok):\n","  synset=wordnet.synsets(item)\n","  print('--------------')\n","  if synset:\n","    r_word=synset[0].lemmas()[0].name()\n","    new_s=sf.replace(item,r_word)\n","  else:\n","    continue\n","  print(f'{item}-->{r_word}')\n","  conf,true,pred=pred_pipeline(BERT_model,new_s,lf)\n","  print(np.around(conf,decimals=3))\n","  if true!=pred:\n","    imp_word.append([item,r_word])\n","\n","imp_word"],"execution_count":null,"outputs":[{"output_type":"stream","text":["sentence alfalfa is the only cure for covid\n","--------------\n","alfalfa-->alfalfa\n","Original-->Fake\n","Predicted-->Fake\n","[[7.5000e-02 9.9885e+01]]\n","--------------\n","is-->be\n","Original-->Fake\n","Predicted-->Fake\n","[[ 0.298 99.627]]\n","--------------\n","--------------\n","only-->lone\n","Original-->Fake\n","Predicted-->Fake\n","[[8.0000e-02 9.9901e+01]]\n","--------------\n","cure-->remedy\n","Original-->Fake\n","Predicted-->Fake\n","[[6.9000e-02 9.9876e+01]]\n","--------------\n","--------------\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HMUN_FVZPIvq","executionInfo":{"status":"ok","timestamp":1625351753123,"user_tz":-120,"elapsed":5575,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"062f8014-5098-4d49-e542-62013b8d4508"},"source":["pred_pipeline(BERT_model,\n","              sf,\n","              lf)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original-->Fake\n","Predicted-->Fake\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(array([[7.5000e-02, 9.9885e+01]], dtype=float32), 1, 1)"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NtIFTmw9POA0","executionInfo":{"status":"ok","timestamp":1625352166646,"user_tz":-120,"elapsed":6159,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"12abd9ee-ee4f-4a49-c192-9749c65810ac"},"source":["pred_pipeline(BERT_model,\n","              'corona',\n","              lf)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original-->Fake\n","Predicted-->Fake\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(array([[ 1.388, 98.576]], dtype=float32), 1, 1)"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tGwc6O6AQamc","executionInfo":{"status":"ok","timestamp":1625287063738,"user_tz":-120,"elapsed":2988,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"6d1dac50-c434-41b0-fafa-50e147273689"},"source":["pred_pipeline(BERT_model,\n","              'two interesting correlation child tend to weather covid pretty well they also get a ton of vitamin d black people are getting  by covid black people also have much higher instance of vitamin d deficiency v in the general population'\n","              ,lf)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original-->Fake\n","Predicted-->Real\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["(array([[59, 41]]), 1, 0)"]},"metadata":{"tags":[]},"execution_count":415}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"tuvyAqeebT_v","executionInfo":{"status":"ok","timestamp":1625285701554,"user_tz":-120,"elapsed":217,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"1552615b-4c7c-4ff1-ad93-721045b9041f"},"source":["sf"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'two interesting correlation child tend to weather covid pretty well they also get a ton of vitamin d black people are getting slammed by covid black people also have much higher instance of vitamin d deficiency v in the general population'"]},"metadata":{"tags":[]},"execution_count":388}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XodBtJfvk6zk","executionInfo":{"status":"ok","timestamp":1625286890339,"user_tz":-120,"elapsed":2749,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"79a1572f-57f0-4397-e531-0ff67bd4f762"},"source":["pred_pipeline(BERT_model,\n","              'higher',\n","              lf)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original-->Fake\n","Predicted-->Real\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["(array([[98,  4]]), 1, 0)"]},"metadata":{"tags":[]},"execution_count":408}]},{"cell_type":"code","metadata":{"id":"kp9a66tcozbT"},"source":[""],"execution_count":null,"outputs":[]}]}