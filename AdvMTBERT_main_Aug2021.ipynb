{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"AdvMTBERT_main_Aug2021.ipynb","provenance":[],"collapsed_sections":["EdLuUoh3IXmf"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8072a715b35840d1a00ca5b745855958":{"model_module":"@jupyter-widgets/controls","model_name":"BoundedIntTextModel","state":{"_view_name":"IntTextView","style":"IPY_MODEL_c7d420b3adf3433cb5a4277fa10ff4c4","_dom_classes":[],"description":"Max Length:","_model_name":"BoundedIntTextModel","max":512,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":100,"_view_count":null,"disabled":false,"_view_module_version":"1.5.0","min":10,"continuous_update":false,"step":10,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_651b5a93e5254c56ba1931beac66edd7"}},"c7d420b3adf3433cb5a4277fa10ff4c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"651b5a93e5254c56ba1931beac66edd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b55550a38a3e4a6584ce26f218ce7993":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","state":{"_options_labels":["2e-05","1e-05","0.001"],"_view_name":"DropdownView","style":"IPY_MODEL_4cb7d14622f846bebd25649842fbfb21","_dom_classes":[],"description":"Learning Rate:","_model_name":"DropdownModel","index":0,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d7c5ee240a4c46e599fac14130d795a2"}},"4cb7d14622f846bebd25649842fbfb21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d7c5ee240a4c46e599fac14130d795a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"342b27fa43464cb1967852b7e9fc3ff9":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","state":{"_options_labels":["3","4","5","6"],"_view_name":"DropdownView","style":"IPY_MODEL_a9601f50a60347fcb71c8c04ffe2634a","_dom_classes":[],"description":"Epochs:","_model_name":"DropdownModel","index":0,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c807a9761e0443e79d212a86e489d79d"}},"a9601f50a60347fcb71c8c04ffe2634a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c807a9761e0443e79d212a86e489d79d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a13400f5df4a482c908db7c4a7f408ca":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","state":{"_options_labels":["4","5","6","7","8"],"_view_name":"DropdownView","style":"IPY_MODEL_a47488a8df06459cb38d3197763536ad","_dom_classes":[],"description":"Batch Size:","_model_name":"DropdownModel","index":0,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2ee178561f8b4b71a8e99a89a8c41526"}},"a47488a8df06459cb38d3197763536ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2ee178561f8b4b71a8e99a89a8c41526":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a0796dad48e747bba5d9b54bb588b999":{"model_module":"@jupyter-widgets/controls","model_name":"BoundedFloatTextModel","state":{"_view_name":"FloatTextView","style":"IPY_MODEL_7a018075514a4e559e90deda3100bdb9","_dom_classes":[],"description":"Alpha:","_model_name":"BoundedFloatTextModel","max":0.999,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0.999,"_view_count":null,"disabled":false,"_view_module_version":"1.5.0","min":0.9,"continuous_update":false,"step":0.001,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b684242461694391af960c546cce5ba1"}},"7a018075514a4e559e90deda3100bdb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b684242461694391af960c546cce5ba1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9fdc3266713d4242a3dd2da82e606f15":{"model_module":"@jupyter-widgets/controls","model_name":"BoundedFloatTextModel","state":{"_view_name":"FloatTextView","style":"IPY_MODEL_d05b18c640564700b9f1d3f97e990388","_dom_classes":[],"description":"Ratio:","_model_name":"BoundedFloatTextModel","max":0.9,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0.5,"_view_count":null,"disabled":false,"_view_module_version":"1.5.0","min":0.1,"continuous_update":false,"step":0.1,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_18237484318c4e4db00669f4a2d277be"}},"d05b18c640564700b9f1d3f97e990388":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"18237484318c4e4db00669f4a2d277be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51a2d158aec045e28c50e2dfa3b56d8d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8a9870f2c1ea424ba9149677573eb1b3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f0dbcbdfdda64bbe96f2fcae8466ad6c","IPY_MODEL_f91c5c5456564cbfb279dd4a205d0efa","IPY_MODEL_c077262c613b40e199e3a238d7435332","IPY_MODEL_92fecca3d45049958baa3e0f99bbde73"]}},"8a9870f2c1ea424ba9149677573eb1b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0dbcbdfdda64bbe96f2fcae8466ad6c":{"model_module":"@jupyter-widgets/controls","model_name":"TextModel","state":{"_view_name":"TextView","style":"IPY_MODEL_abd5287ead554589b4bab25958cb8e5c","_dom_classes":[],"description":"Feature Column:","_model_name":"TextModel","placeholder":"Enter Feature Col Name","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"tweet","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","continuous_update":true,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1ae7bd29235542ab9a11e9f478de3e3c"}},"f91c5c5456564cbfb279dd4a205d0efa":{"model_module":"@jupyter-widgets/controls","model_name":"TextModel","state":{"_view_name":"TextView","style":"IPY_MODEL_0aeaed03046f4c068e5f84be2d489186","_dom_classes":[],"description":"Target Column:","_model_name":"TextModel","placeholder":"Enter Target Col Name","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"label","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","continuous_update":true,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ecb916d774fd4224be14f8d9d5f0a463"}},"c077262c613b40e199e3a238d7435332":{"model_module":"@jupyter-widgets/controls","model_name":"TextModel","state":{"_view_name":"TextView","style":"IPY_MODEL_c8cd4658f7b940d389b31671da23483e","_dom_classes":[],"description":"Augment Column:","_model_name":"TextModel","placeholder":"Enter Augmented data Col Name","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"aug_tweet","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","continuous_update":true,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3d47ce59ce974ef29a45d0f014795173"}},"92fecca3d45049958baa3e0f99bbde73":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","state":{"_options_labels":["bert-base-uncased","distilbert-base-uncased"],"_view_name":"DropdownView","style":"IPY_MODEL_d086ada708094ec48e517edf7199a380","_dom_classes":[],"description":"Pretrained Model:","_model_name":"DropdownModel","index":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a98f906e69ff471d8b40e5a183fb6dc7"}},"abd5287ead554589b4bab25958cb8e5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1ae7bd29235542ab9a11e9f478de3e3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0aeaed03046f4c068e5f84be2d489186":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ecb916d774fd4224be14f8d9d5f0a463":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c8cd4658f7b940d389b31671da23483e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3d47ce59ce974ef29a45d0f014795173":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d086ada708094ec48e517edf7199a380":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a98f906e69ff471d8b40e5a183fb6dc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1baf09fa225c47f090c2c620dc8aaff5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2aa549f4b7584781b007eb505fc4df1d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1b9fcfc6f4f24659b764df3aa1faffe1"]}},"2aa549f4b7584781b007eb505fc4df1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1b9fcfc6f4f24659b764df3aa1faffe1":{"model_module":"@jupyter-widgets/controls","model_name":"TextModel","state":{"_view_name":"TextView","style":"IPY_MODEL_67a782c5127a4fad8c8e34dd4bf354ec","_dom_classes":[],"description":" Data Location Column:","_model_name":"TextModel","placeholder":"Enter Data location ","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Data/codalab/","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","continuous_update":true,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d4b6538af050415aaa19e2011483a29e"}},"67a782c5127a4fad8c8e34dd4bf354ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d4b6538af050415aaa19e2011483a29e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3d51352ceec9452d91f5cc5460eeb8e4":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","state":{"_options_labels":["BERT","DistillBERT"],"_view_name":"DropdownView","style":"IPY_MODEL_ea52a7ab8aa645349de77ca305dfd996","_dom_classes":[],"description":"Model Name:","_model_name":"DropdownModel","index":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_447603d948814085a8316dd78c11923d"}},"ea52a7ab8aa645349de77ca305dfd996":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"447603d948814085a8316dd78c11923d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6879e0e4e75a4ec2b145f1d4df4c839d":{"model_module":"@jupyter-widgets/controls","model_name":"BoundedIntTextModel","state":{"_view_name":"IntTextView","style":"IPY_MODEL_504ef01177274d2f8d98b9a2c583685b","_dom_classes":[],"description":"Query Budget:","_model_name":"BoundedIntTextModel","max":500,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":200,"_view_count":null,"disabled":false,"_view_module_version":"1.5.0","min":10,"continuous_update":false,"step":20,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2447e77bff9d4e0e8fd2630b072bd2a9"}},"504ef01177274d2f8d98b9a2c583685b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2447e77bff9d4e0e8fd2630b072bd2a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f8d0232ab5ba4c10afd05d9844e3a05b":{"model_module":"@jupyter-widgets/controls","model_name":"BoundedIntTextModel","state":{"_view_name":"IntTextView","style":"IPY_MODEL_4af2f8999ab1431a9dd6dd8242a4545c","_dom_classes":[],"description":"Number of Example:","_model_name":"BoundedIntTextModel","max":2040,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":500,"_view_count":null,"disabled":false,"_view_module_version":"1.5.0","min":10,"continuous_update":false,"step":20,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d0cfb3c2de9a4fc2a481017ba3824190"}},"4af2f8999ab1431a9dd6dd8242a4545c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d0cfb3c2de9a4fc2a481017ba3824190":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"438d6dfdab294831844b79c1f05ee674":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","state":{"_options_labels":["TextFoolerJin2019","PWWSRen2019","BERTAttackLi2020","BAEGarg2019","TextBuggerLi2018"],"_view_name":"DropdownView","style":"IPY_MODEL_7bb1f912fc2c461d84d7870b7be53a30","_dom_classes":[],"description":"Attack Recipe:","_model_name":"DropdownModel","index":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"disabled":false,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_708cc80684da490ea5d5a9028db2578f"}},"7bb1f912fc2c461d84d7870b7be53a30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"708cc80684da490ea5d5a9028db2578f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"SHlXSc7PA1__"},"source":["# Mean Teacher Bert Assessment\n","\n"]},{"cell_type":"markdown","metadata":{"id":"KNOd8hxPIUV_"},"source":["# Requirement Installation "]},{"cell_type":"code","metadata":{"id":"Qr7uacDbBSEi","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1627942249937,"user_tz":-120,"elapsed":184204,"user":{"displayName":"Bhupender Kumar Saini","photoUrl":"","userId":"04265374379702190944"}},"outputId":"ecbfc03b-1b8e-4108-b7d3-24f12b4c48f3"},"source":["#installing requirements\n","!pip install textattack==0.3.0"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting textattack==0.3.0\n","  Downloading textattack-0.3.0-py3-none-any.whl (359 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 40 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 51 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 61 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 71 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 81 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 92 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 102 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 112 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 122 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 133 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 143 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 153 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 163 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 174 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 184 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 194 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 204 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 215 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 225 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 235 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 245 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 256 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 266 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 276 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 286 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 296 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 307 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 317 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 327 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 337 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 348 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 358 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 359 kB 7.8 MB/s \n","\u001b[?25hCollecting datasets\n","  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n","\u001b[?25l\r\u001b[K     |█▎                              | 10 kB 55.2 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 20 kB 58.9 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 30 kB 63.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 40 kB 56.4 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 51 kB 58.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 61 kB 62.5 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 71 kB 64.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 81 kB 65.6 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 92 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 102 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 112 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 122 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 133 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 143 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 153 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 163 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 174 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 184 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 194 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 204 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 215 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 225 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 235 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 245 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 256 kB 62.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 264 kB 62.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from textattack==0.3.0) (4.41.1)\n","Collecting lru-dict\n","  Downloading lru-dict-1.1.7.tar.gz (10 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from textattack==0.3.0) (3.0.12)\n","Collecting bert-score>=0.3.5\n","  Downloading bert_score-0.3.9-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from textattack==0.3.0) (8.8.0)\n","Collecting flair\n","  Downloading flair-0.8.0.post1-py3-none-any.whl (284 kB)\n","\u001b[K     |████████████████████████████████| 284 kB 60.1 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from textattack==0.3.0) (1.1.5)\n","Collecting numpy<1.19.0\n","  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n","\u001b[K     |████████████████████████████████| 20.1 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from textattack==0.3.0) (0.5.3)\n","Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from textattack==0.3.0) (1.4.1)\n","Collecting torch==1.7.1\n","  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n","\u001b[K     |████████████████████████████████| 776.8 MB 18 kB/s \n","\u001b[?25hCollecting terminaltables\n","  Downloading terminaltables-3.1.0.tar.gz (12 kB)\n","Collecting num2words\n","  Downloading num2words-0.5.10-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 13.3 MB/s \n","\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from textattack==0.3.0) (1.7.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from textattack==0.3.0) (3.2.5)\n","Collecting word2number\n","  Downloading word2number-1.1.zip (9.7 kB)\n","Collecting language-tool-python\n","  Downloading language_tool_python-2.5.5-py3-none-any.whl (31 kB)\n","Collecting transformers>=3.3.0\n","  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 64.1 MB/s \n","\u001b[?25hCollecting lemminflect\n","  Downloading lemminflect-0.2.2-py3-none-any.whl (769 kB)\n","\u001b[K     |████████████████████████████████| 769 kB 56.3 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->textattack==0.3.0) (3.7.4.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bert-score>=0.3.5->textattack==0.3.0) (2.23.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bert-score>=0.3.5->textattack==0.3.0) (3.2.2)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->textattack==0.3.0) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->textattack==0.3.0) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->textattack==0.3.0) (1.15.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.3.0->textattack==0.3.0) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 57.0 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 66.3 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 58.3 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.3.0->textattack==0.3.0) (4.6.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=3.3.0->textattack==0.3.0) (21.0)\n","Collecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=3.3.0->textattack==0.3.0) (2.4.7)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 63.2 MB/s \n","\u001b[?25hCollecting fsspec>=2021.05.0\n","  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n","\u001b[K     |████████████████████████████████| 118 kB 79.4 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets->textattack==0.3.0) (0.3.4)\n","Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->textattack==0.3.0) (3.0.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->textattack==0.3.0) (0.70.12.2)\n","Collecting tqdm<4.50.0,>=4.27\n","  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n","\u001b[K     |████████████████████████████████| 69 kB 10.4 MB/s \n","\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score>=0.3.5->textattack==0.3.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score>=0.3.5->textattack==0.3.0) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score>=0.3.5->textattack==0.3.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score>=0.3.5->textattack==0.3.0) (2.10)\n","Collecting segtok>=1.5.7\n","  Downloading segtok-1.5.10.tar.gz (25 kB)\n","Collecting bpemb>=0.3.2\n","  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n","Collecting sqlitedict>=1.6.0\n","  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair->textattack==0.3.0) (0.22.2.post1)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair->textattack==0.3.0) (4.2.6)\n","Collecting ftfy\n","  Downloading ftfy-6.0.3.tar.gz (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 3.4 MB/s \n","\u001b[?25hCollecting konoha<5.0.0,>=4.0.0\n","  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n","Collecting sentencepiece==0.1.95\n","  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 49.3 MB/s \n","\u001b[?25hCollecting mpld3==0.3\n","  Downloading mpld3-0.3.tar.gz (788 kB)\n","\u001b[K     |████████████████████████████████| 788 kB 55.4 MB/s \n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair->textattack==0.3.0) (0.8.9)\n","Collecting janome\n","  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n","\u001b[K     |████████████████████████████████| 19.7 MB 1.4 MB/s \n","\u001b[?25hRequirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair->textattack==0.3.0) (3.6.0)\n","Collecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[K     |████████████████████████████████| 981 kB 60.7 MB/s \n","\u001b[?25hCollecting gdown==3.12.2\n","  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair->textattack==0.3.0) (0.1.2)\n","Collecting deprecated>=1.2.4\n","  Downloading Deprecated-1.2.12-py2.py3-none-any.whl (9.5 kB)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair->textattack==0.3.0) (1.12.1)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair->textattack==0.3.0) (5.1.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair->textattack==0.3.0) (0.16.0)\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair->textattack==0.3.0) (3.11.4)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair->textattack==0.3.0) (2.5.1)\n","Collecting importlib-metadata\n","  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n","Collecting requests\n","  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.2 MB/s \n","\u001b[?25hCollecting overrides<4.0.0,>=3.0.0\n","  Downloading overrides-3.1.0.tar.gz (11 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.3.0->textattack==0.3.0) (3.5.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score>=0.3.5->textattack==0.3.0) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score>=0.3.5->textattack==0.3.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score>=0.3.5->textattack==0.3.0) (2.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair->textattack==0.3.0) (1.0.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair->textattack==0.3.0) (0.2.5)\n","Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt>=0.1.1->flair->textattack==0.3.0) (4.4.2)\n","Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words->textattack==0.3.0) (0.6.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.3.0->textattack==0.3.0) (7.1.2)\n","Building wheels for collected packages: gdown, mpld3, overrides, segtok, sqlitedict, ftfy, langdetect, lru-dict, terminaltables, word2number\n","  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9705 sha256=7485be70ed2403d2de3acd72f5a891ef2ef2ba4965e548da7fc0571d1aab7bd1\n","  Stored in directory: /root/.cache/pip/wheels/ba/e0/7e/726e872a53f7358b4b96a9975b04e98113b005cd8609a63abc\n","  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116701 sha256=682c36dfa85d4eaf2cb2a6b145bc84d62a8abdf2a0f03bf20183a25732802f4e\n","  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10188 sha256=0d9d740d50d1facd09d569115119fffef959872133765b23b2a77d6592639570\n","  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n","  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25030 sha256=7804f9f01db83fccfc9d7b733d3db263d24a30138dc2f26df008109fcfc4f830\n","  Stored in directory: /root/.cache/pip/wheels/67/b7/d0/a121106e61339eee5ed083bc230b1c8dc422c49a5a28c2addd\n","  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14392 sha256=9b50a04f5de83d465264d7c469d566cfec61b85e104feb6bb6120831e9c73917\n","  Stored in directory: /root/.cache/pip/wheels/af/94/06/18c0e83e9e227da8f3582810b51f319bbfd181e508676a56c8\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41934 sha256=abf4ae1b178d7b08d7110b3ebc6dde19b440af32b7ec1ffa215ed567f5917cb2\n","  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993241 sha256=3790f987d4512d1052d18f54543891c7d54142be974d30db6824717096149a87\n","  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n","  Building wheel for lru-dict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lru-dict: filename=lru_dict-1.1.7-cp37-cp37m-linux_x86_64.whl size=28412 sha256=98b539488d678a19613995aa3a4381c9278d9009dad5aa811ae1e1825c280db9\n","  Stored in directory: /root/.cache/pip/wheels/9d/0b/4e/aa8fec9833090cd52bcd76f92f9d95e1ee7b915c12093663b4\n","  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15355 sha256=7982684c54d07756c7f0145febdf957d0dcd9652f9dfdbbc2023bf61ea6a0919\n","  Stored in directory: /root/.cache/pip/wheels/ba/ad/c8/2d98360791161cd3db6daf6b5e730f34021fc9367d5879f497\n","  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5581 sha256=ab695fdf9af9c3ead09362c7a28854c16cabd37ea0c4fd30f9d8fc1c2f83b801\n","  Stored in directory: /root/.cache/pip/wheels/4b/c3/77/a5f48aeb0d3efb7cd5ad61cbd3da30bbf9ffc9662b07c9f879\n","Successfully built gdown mpld3 overrides segtok sqlitedict ftfy langdetect lru-dict terminaltables word2number\n","Installing collected packages: numpy, tqdm, requests, importlib-metadata, tokenizers, sentencepiece, sacremoses, pyyaml, overrides, huggingface-hub, xxhash, transformers, torch, sqlitedict, segtok, mpld3, langdetect, konoha, janome, gdown, ftfy, fsspec, deprecated, bpemb, word2number, terminaltables, num2words, lru-dict, lemminflect, language-tool-python, flair, datasets, bert-score, textattack\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 4.6.1\n","    Uninstalling importlib-metadata-4.6.1:\n","      Successfully uninstalled importlib-metadata-4.6.1\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0+cu102\n","    Uninstalling torch-1.9.0+cu102:\n","      Successfully uninstalled torch-1.9.0+cu102\n","  Attempting uninstall: gdown\n","    Found existing installation: gdown 3.6.4\n","    Uninstalling gdown-3.6.4:\n","      Successfully uninstalled gdown-3.6.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\n","torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\n","tensorflow 2.5.0 requires numpy~=1.19.2, but you have numpy 1.18.5 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed bert-score-0.3.9 bpemb-0.3.3 datasets-1.11.0 deprecated-1.2.12 flair-0.8.0.post1 fsspec-2021.7.0 ftfy-6.0.3 gdown-3.12.2 huggingface-hub-0.0.12 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.5 langdetect-1.0.9 language-tool-python-2.5.5 lemminflect-0.2.2 lru-dict-1.1.7 mpld3-0.3 num2words-0.5.10 numpy-1.18.5 overrides-3.1.0 pyyaml-5.4.1 requests-2.26.0 sacremoses-0.0.45 segtok-1.5.10 sentencepiece-0.1.95 sqlitedict-1.7.0 terminaltables-3.1.0 textattack-0.3.0 tokenizers-0.10.3 torch-1.7.1 tqdm-4.49.0 transformers-4.9.1 word2number-1.1 xxhash-2.0.2\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"7ukrY3nW8U-N"},"source":["# Importing and Declaration"]},{"cell_type":"code","metadata":{"id":"j5ijH3uLgK20","executionInfo":{"status":"ok","timestamp":1627942249939,"user_tz":-120,"elapsed":10,"user":{"displayName":"Bhupender Kumar Saini","photoUrl":"","userId":"04265374379702190944"}}},"source":["import os \n","os.chdir('/content/drive/MyDrive/Master Thesis/Mean-Teacher-BERT-assessment/')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"14d38BPsrMbn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627942290768,"user_tz":-120,"elapsed":40836,"user":{"displayName":"Bhupender Kumar Saini","photoUrl":"","userId":"04265374379702190944"}},"outputId":"cd59e48e-9d30-4947-a931-36e90f69886b"},"source":["# importing libraries \n","import os \n","import pandas as pd \n","import numpy as np\n","import tensorflow as tf\n","\n","from ipywidgets import *\n","from IPython.display import display\n","\n","\n","from Utils.utils import label_to_int, dataset_split, convert_to_category, create_tokenizer, data_tokenization\n","from Utils.data_loader import data_loader\n","from Bert.bert_model import bert_model\n","from Attack_model.TextAttack import attack_model\n","\n","\n","from MeanTeacher.train_mean_teacher import train_mean_teacher\n","\n","import random \n","random.seed(42)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["textattack: Updating TextAttack package dependencies.\n","textattack: Downloading NLTK required packages.\n"],"name":"stderr"},{"output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package omw to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/omw.zip.\n","[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n","[nltk_data]   Unzipping taggers/universal_tagset.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"stream","text":["textattack: Downloading https://textattack.s3.amazonaws.com/word_embeddings/paragramcf.\n","100%|██████████| 481M/481M [00:12<00:00, 40.0MB/s]\n","textattack: Unzipping file /root/.cache/textattack/tmppnkd557_.zip to /root/.cache/textattack/word_embeddings/paragramcf.\n","textattack: Successfully saved word_embeddings/paragramcf to cache.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"UqPYofJNhq4M"},"source":["# Hyperparameter selections"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":413,"referenced_widgets":["8072a715b35840d1a00ca5b745855958","c7d420b3adf3433cb5a4277fa10ff4c4","651b5a93e5254c56ba1931beac66edd7","b55550a38a3e4a6584ce26f218ce7993","4cb7d14622f846bebd25649842fbfb21","d7c5ee240a4c46e599fac14130d795a2","342b27fa43464cb1967852b7e9fc3ff9","a9601f50a60347fcb71c8c04ffe2634a","c807a9761e0443e79d212a86e489d79d","a13400f5df4a482c908db7c4a7f408ca","a47488a8df06459cb38d3197763536ad","2ee178561f8b4b71a8e99a89a8c41526","a0796dad48e747bba5d9b54bb588b999","7a018075514a4e559e90deda3100bdb9","b684242461694391af960c546cce5ba1","9fdc3266713d4242a3dd2da82e606f15","d05b18c640564700b9f1d3f97e990388","18237484318c4e4db00669f4a2d277be"]},"id":"EoDFiVRXKaZ2","executionInfo":{"status":"ok","timestamp":1627942296453,"user_tz":-120,"elapsed":5687,"user":{"displayName":"Bhupender Kumar Saini","photoUrl":"","userId":"04265374379702190944"}},"outputId":"767057aa-fada-41a0-88e3-fa23908166fa"},"source":["# Parameter declaration \n","max_len=widgets.BoundedIntText(value=100,min=10,max=512,step=10,description='Max Length:',disabled=False,)\n","\n","learning_rate= widgets.Dropdown(options=[2e-5, 1e-5, 1e-3],value=2e-5,description='Learning Rate:',disabled=False,)\n","\n","epochs= widgets.Dropdown(options=[3, 4, 5,6],value=3,description='Epochs:',disabled=False,)\n","\n","batch_size= widgets.Dropdown(options=[4, 5,6,7,8],value=4,description='Batch Size:',disabled=False,)\n","\n","#for mean teacher model\n","alpha= widgets.BoundedFloatText(value=0.999,min=0.90,max=0.999,step=0.001,description='Alpha:',disabled=False, readout_format='.3f')\n","ratio= widgets.BoundedFloatText(value=0.5,min=0.1,max=0.9,step=0.1,description='Ratio:',disabled=False, readout_format='.2f')\n","\n","tf.print('\\n Max Length: Length of the article')\n","display(max_len)\n","tf.print('\\n Learning rate: Learning rate for training the model')\n","display(learning_rate)\n","tf.print('\\n Epochs')\n","display(epochs)\n","tf.print('\\n batch_size')\n","display(batch_size)\n","tf.print('\\n Alpha: Parameter related to Mean teacher model, its the proportion of student weight that teacher model will get each step.')\n","display(alpha)\n","tf.print(\"\\n Ratio: Parameter related to Mean Teacher model, that manage the proportion of classification cost and consistency cost in calculating overall cost.\")\n","display(ratio)\n","# widgets.HBox([max_len, learning_rate, epochs, batch_size,alpha,ratio])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["\n"," Max Length: Length of the article\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8072a715b35840d1a00ca5b745855958","version_minor":0,"version_major":2},"text/plain":["BoundedIntText(value=100, description='Max Length:', max=512, min=10, step=10)"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"," Learning rate: Learning rate for training the model\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b55550a38a3e4a6584ce26f218ce7993","version_minor":0,"version_major":2},"text/plain":["Dropdown(description='Learning Rate:', options=(2e-05, 1e-05, 0.001), value=2e-05)"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"," Epochs\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"342b27fa43464cb1967852b7e9fc3ff9","version_minor":0,"version_major":2},"text/plain":["Dropdown(description='Epochs:', options=(3, 4, 5, 6), value=3)"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"," batch_size\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a13400f5df4a482c908db7c4a7f408ca","version_minor":0,"version_major":2},"text/plain":["Dropdown(description='Batch Size:', options=(4, 5, 6, 7, 8), value=4)"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"," Alpha: Parameter related to Mean teacher model, its the proportion of student weight that teacher model will get each step.\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0796dad48e747bba5d9b54bb588b999","version_minor":0,"version_major":2},"text/plain":["BoundedFloatText(value=0.999, description='Alpha:', max=0.999, min=0.9, step=0.001)"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"," Ratio: Parameter related to Mean Teacher model, that manage the proportion of classification cost and consistency cost in calculating overall cost.\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9fdc3266713d4242a3dd2da82e606f15","version_minor":0,"version_major":2},"text/plain":["BoundedFloatText(value=0.5, description='Ratio:', max=0.9, min=0.1, step=0.1)"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["51a2d158aec045e28c50e2dfa3b56d8d","8a9870f2c1ea424ba9149677573eb1b3","f0dbcbdfdda64bbe96f2fcae8466ad6c","f91c5c5456564cbfb279dd4a205d0efa","c077262c613b40e199e3a238d7435332","92fecca3d45049958baa3e0f99bbde73","abd5287ead554589b4bab25958cb8e5c","1ae7bd29235542ab9a11e9f478de3e3c","0aeaed03046f4c068e5f84be2d489186","ecb916d774fd4224be14f8d9d5f0a463","c8cd4658f7b940d389b31671da23483e","3d47ce59ce974ef29a45d0f014795173","d086ada708094ec48e517edf7199a380","a98f906e69ff471d8b40e5a183fb6dc7"]},"id":"TC5DyUDfLg7S","executionInfo":{"status":"ok","timestamp":1627942296454,"user_tz":-120,"elapsed":11,"user":{"displayName":"Bhupender Kumar Saini","photoUrl":"","userId":"04265374379702190944"}},"outputId":"3f6a19b9-d342-4cc9-85e9-83b235b8e499"},"source":["# Details related to the dataset\n","# columns names \n","feature_col=widgets.Text(value='tweet',placeholder='Enter Feature Col Name',description='Feature Column:',disabled=False)\n","target_col=widgets.Text(value='label',placeholder='Enter Target Col Name',description='Target Column:',disabled=False) \n","aug_col=widgets.Text(value='aug_tweet',placeholder='Enter Augmented data Col Name',description='Augment Column:',disabled=False)   \n","\n","#pretrained model details\n","pretrained_weights=widgets.Dropdown(options=['bert-base-uncased','distilbert-base-uncased' ],value='bert-base-uncased',description='Pretrained Model:',disabled=False,) \n","\n","widgets.HBox([feature_col,target_col,aug_col,pretrained_weights])"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51a2d158aec045e28c50e2dfa3b56d8d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(Text(value='tweet', description='Feature Column:', placeholder='Enter Feature Col Name'), Text(…"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["1baf09fa225c47f090c2c620dc8aaff5","2aa549f4b7584781b007eb505fc4df1d","1b9fcfc6f4f24659b764df3aa1faffe1","67a782c5127a4fad8c8e34dd4bf354ec","d4b6538af050415aaa19e2011483a29e"]},"id":"BRl-nQdyNPNf","executionInfo":{"status":"ok","timestamp":1627942296454,"user_tz":-120,"elapsed":9,"user":{"displayName":"Bhupender Kumar Saini","photoUrl":"","userId":"04265374379702190944"}},"outputId":"9c73b96d-314c-44fb-f633-fa3e50718733"},"source":["#Data location \n","Data_loc=widgets.Text(value='Data/codalab/',placeholder='Enter Data location ',description=' Data Location Column:',disabled=False)   \n","widgets.HBox([Data_loc])"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1baf09fa225c47f090c2c620dc8aaff5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(Text(value='Data/codalab/', description=' Data Location Column:', placeholder='Enter Data locat…"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"EdLuUoh3IXmf"},"source":["# Reading dataset"]},{"cell_type":"code","metadata":{"id":"HG9vVBYM_9rD","executionInfo":{"status":"ok","timestamp":1627942426435,"user_tz":-120,"elapsed":3263,"user":{"displayName":"Bhupender Kumar Saini","photoUrl":"","userId":"04265374379702190944"}}},"source":["df_train,df_test,df_aug_unlabel= data_loader(Data_loc.value,target_col.value,aug_col.value)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aMRIbRm-hybg"},"source":["# Training \n","\n","<font color='blue'>This section is to train and save the model. <br>\n","__If model is already trained and saved, directly move forward for attack and evaluation section.__ </font>"]},{"cell_type":"markdown","metadata":{"id":"XFFW8oMci-1D"},"source":["## BERT Model Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"H0s7YpUu3z-Q","executionInfo":{"status":"ok","timestamp":1627933249729,"user_tz":-120,"elapsed":753,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"13937ad6-2960-4dc5-a8e4-5d8ae4d737c4"},"source":["pretrained_weights.value"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'bert-base-uncased'"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"kSfsn7Fwjj7A"},"source":["tokenizer=create_tokenizer(pretrained_weights.value)\n","x_train,y_train,vocab_size= data_tokenization(df_train,feature_col.value,target_col.value,max_len.value,tokenizer)\n","x_test,y_test,_= data_tokenization(df_test,feature_col.value,target_col.value,max_len.value,tokenizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HLx8dwSQjuYO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627933548231,"user_tz":-120,"elapsed":4517,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"598e485b-88ce-4101-ecbe-45a63a57547c"},"source":["bert=bert_model(pretrained_weights.value,max_len.value,learning_rate.value)\n","bert.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_5\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_ids (InputLayer)          [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","attention_mask (InputLayer)     [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","tf_bert_model_2 (TFBertModel)   TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n","                                                                 attention_mask[0][0]             \n","__________________________________________________________________________________________________\n","tf.__operators__.getitem_5 (Sli (None, 768)          0           tf_bert_model_2[0][0]            \n","__________________________________________________________________________________________________\n","dropout_173 (Dropout)           (None, 768)          0           tf.__operators__.getitem_5[0][0] \n","__________________________________________________________________________________________________\n","dense_15 (Dense)                (None, 64)           49216       dropout_173[0][0]                \n","__________________________________________________________________________________________________\n","dense_16 (Dense)                (None, 32)           2080        dense_15[0][0]                   \n","__________________________________________________________________________________________________\n","dense_17 (Dense)                (None, 2)            66          dense_16[0][0]                   \n","==================================================================================================\n","Total params: 109,533,602\n","Trainable params: 109,533,602\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Dpvp4CADj_FP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627934730738,"user_tz":-120,"elapsed":1182515,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"74432181-6075-4c95-d56b-c6f0cdce53d0"},"source":["with tf.device('/GPU:0'):\n","    bert.fit(x_train,y_train,batch_size=batch_size.value,epochs=epochs.value,verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["1523/1523 [==============================] - 408s 255ms/step - loss: 0.2502 - accuracy: 0.8975\n","Epoch 2/3\n","1523/1523 [==============================] - 387s 254ms/step - loss: 0.0839 - accuracy: 0.9698\n","Epoch 3/3\n","1523/1523 [==============================] - 388s 254ms/step - loss: 0.0312 - accuracy: 0.9908\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j_zSEJNFdyIs"},"source":["#saving the model \n","if  pretrained_weights.value == 'distilbert-base-uncased':\n","    bert.save_weights('SavedModels/Codalab/DistillBERT_model.h5')\n","else:\n","    bert.save_weights('SavedModels/Codalab/BERT_model.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M-zuATWcosoS"},"source":["## Adversarial Mean Teacher BERT Training"]},{"cell_type":"code","metadata":{"id":"0omohUC3segj"},"source":["# Training\n","tokenizer=create_tokenizer(pretrained_weights.value)\n","x_train,y_train,vocab_size= data_tokenization(df_train,feature_col.value,target_col.value,max_len.value,tokenizer)\n","x_test,y_test,_= data_tokenization(df_test,feature_col.value,target_col.value,max_len.value,tokenizer)\n","x_unlabel,_,_=data_tokenization(df_aug_unlabel,aug_col.value,target_col.value,max_len.value,tokenizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kqbv7MDNMYw9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627933171485,"user_tz":-120,"elapsed":6659190,"user":{"displayName":"Bhupender saini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjW1nYjUjrI6fSCoD9rs8R5pgZbi6VAk4jGbR0NYA=s64","userId":"10265617276189948004"}},"outputId":"acfd1d29-09d1-4969-baa6-b06de9eae93f"},"source":["\n","with tf.device('/GPU:0'):\n","    student, teacher= train_mean_teacher(x_train, y_train, x_unlabel, \n","                                         pretrained_weights.value,\n","                                         epochs.value,batch_size.value,\n","                                         learning_rate.value,max_len.value,alpha.value)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'vocab_layer_norm', 'vocab_transform', 'activation_13']\n","- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'vocab_layer_norm', 'vocab_transform', 'activation_13']\n","- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["alpha: 0.999\n","\n","epoch 1\n","1522/1523 [============================>.] - ETA: 1s - Accuracy: 0.6991 - Overall_Loss: 0.0982\n","epoch 2\n","1522/1523 [============================>.] - ETA: 1s - Accuracy: 0.8422 - Overall_Loss: 0.0223\n","epoch 3\n","1522/1523 [============================>.] - ETA: 1s - Accuracy: 0.8946 - Overall_Loss: 0.0065"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-Jn16TnmL-2I"},"source":["if  pretrained_weights.value == 'distilbert-base-uncased':\n","    teacher.save_weights('SavedModels/Codalab/DistillBERT_teacher.h5')\n","else:\n","    teacher.save_weights('SavedModels/Codalab/BERT_teacher.h5')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CuBF7YPDoIrz"},"source":["# Attack And Evaluation"]},{"cell_type":"code","metadata":{"id":"CbBJBqWMd6Q8","executionInfo":{"status":"ok","timestamp":1627942336623,"user_tz":-120,"elapsed":241,"user":{"displayName":"Bhupender Kumar Saini","photoUrl":"","userId":"04265374379702190944"}}},"source":["import textattack"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":83,"referenced_widgets":["3d51352ceec9452d91f5cc5460eeb8e4","ea52a7ab8aa645349de77ca305dfd996","447603d948814085a8316dd78c11923d"]},"id":"HWxkl329bvuy","executionInfo":{"status":"ok","timestamp":1627942407594,"user_tz":-120,"elapsed":368,"user":{"displayName":"Bhupender Kumar Saini","photoUrl":"","userId":"04265374379702190944"}},"outputId":"24d4e9b8-a358-46f4-c368-c106b4c043d1"},"source":["# bert_to_attack=widgets.Textarea(value='SavedModels/Codalab/BERT_model.h5',placeholder='Enter Model location ',description=' BERT Model location:',disabled=False)\n","# MTbert_to_attack=widgets.Textarea(value='SavedModels/Codalab/BERT_teacher.h5',placeholder='Enter Model location ',description=' MTBERT Model location:',disabled=False)   \n","# pretrained_weights=widgets.Dropdown(options=['bert-base-uncased','distilbert-base-uncased' ],value='bert-base-uncased',description='Pretrained Model:',disabled=False,) \n","model_name=widgets.Dropdown(options=['BERT','DistillBERT']\n","                               ,value='BERT',\n","                               description='Model Name:',\n","                               disabled=False,) \n","tf.print('\\n model_name: Model name for attack.Note : Please confirm with the bert_to_attack parameter')\n","display(model_name)\n","if model_name=='BERT':\n","  bert_to_attack= 'SavedModels/Codalab/BERT_model.h5'\n","  MTbert_to_attack='SavedModels/Codalab/BERT_teacher.h5'\n","  pretrained_weights.value = 'bert-base-uncased'\n","else:\n","  bert_to_attack= 'SavedModels/Codalab/DistillBERT_model.h5'\n","  MTbert_to_attack='SavedModels/Codalab/DistillBERT_teacher.h5'\n","  pretrained_weights.value = 'distilbert-base-uncased'\n","\n","\n","# tf.print('\\n Please select the location of BERT and MT BERT model.\\n')\n","# display(bert_to_attack, MTbert_to_attack)\n","# tf.print('\\n Please select the pretrained model weights.')\n","# display(pretrained_weights)\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["\n"," model_name: Model name for attack.Note : Please confirm with the bert_to_attack parameter\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d51352ceec9452d91f5cc5460eeb8e4","version_minor":0,"version_major":2},"text/plain":["Dropdown(description='Model Name:', options=('BERT', 'DistillBERT'), value='BERT')"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mtize46W7nJk","executionInfo":{"status":"ok","timestamp":1627942469468,"user_tz":-120,"elapsed":343,"user":{"displayName":"Bhupender Kumar Saini","photoUrl":"","userId":"04265374379702190944"}},"outputId":"f246bdac-d504-485c-86ad-b3eeee86c6c8"},"source":["print(model_name.value)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["DistillBERT\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":215,"referenced_widgets":["6879e0e4e75a4ec2b145f1d4df4c839d","504ef01177274d2f8d98b9a2c583685b","2447e77bff9d4e0e8fd2630b072bd2a9","f8d0232ab5ba4c10afd05d9844e3a05b","4af2f8999ab1431a9dd6dd8242a4545c","d0cfb3c2de9a4fc2a481017ba3824190","438d6dfdab294831844b79c1f05ee674","7bb1f912fc2c461d84d7870b7be53a30","708cc80684da490ea5d5a9028db2578f"]},"id":"W_XIBNp3e-Bu","executionInfo":{"status":"ok","timestamp":1627942476928,"user_tz":-120,"elapsed":360,"user":{"displayName":"Bhupender Kumar Saini","photoUrl":"","userId":"04265374379702190944"}},"outputId":"96a9a1d4-a6b3-48cc-a70b-f6ec403f3ab5"},"source":["# attack parameters \n","\n","# Query Budget is maximum query allowed\n","query_budget= widgets.BoundedIntText(value=200,min=10,max=500,step=20,description='Query Budget:',disabled=False,)\n","\n","# number of example to take for attack from test dataset randomly \n","num_examples=widgets.BoundedIntText(value=200,min=10,max=len(df_test),step=20,description='Number of Example:',disabled=False,)\n","\n","# attack recipes \n","attack_recipe=widgets.Dropdown(options=['TextFoolerJin2019','PWWSRen2019','BERTAttackLi2020','BAEGarg2019','TextBuggerLi2018']\n","                               ,value='TextFoolerJin2019',\n","                               description='Attack Recipe:',\n","                               disabled=False,) \n","\n","\n","tf.print('\\n query_budget: Maximum Query allowed to attack model')\n","display(query_budget)\n","tf.print('\\n num_examples: Number of example to take for attack from test dataset randomly. ')\n","display(num_examples)\n","tf.print('\\n attack_recipe: Attack methodolgy to attack the model. ')\n","display(attack_recipe)\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["\n"," query_budget: Maximum Query allowed to attack model\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6879e0e4e75a4ec2b145f1d4df4c839d","version_minor":0,"version_major":2},"text/plain":["BoundedIntText(value=200, description='Query Budget:', max=500, min=10, step=20)"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"," num_examples: Number of example to take for attack from test dataset randomly. \n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8d0232ab5ba4c10afd05d9844e3a05b","version_minor":0,"version_major":2},"text/plain":["BoundedIntText(value=200, description='Number of Example:', max=2040, min=10, step=20)"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"," attack_recipe: Attack methodolgy to attack the model. \n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"438d6dfdab294831844b79c1f05ee674","version_minor":0,"version_major":2},"text/plain":["Dropdown(description='Attack Recipe:', options=('TextFoolerJin2019', 'PWWSRen2019', 'BERTAttackLi2020', 'BAEGa…"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"sEJPmPJVuV76"},"source":["- __PWWSRen 2019 - Generating Natural Language Adversarial Examples through Probability Weighted Word Saliency. Shuhuai Ren, Yihe Deng, Kun He, Wanxiang Che__<br>\n","Based on the synonyms substitution strategy, they introduced a new word replacement order determined by both the word saliency and the classification probability, and propose a greedy algorithm called probability weighted word saliency (PWWS) for text adversarial attack.\n","- __TextFoolerJin2019 - Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment.__<br>\n","In this paper, we present TextFooler, a simple but strong baseline to generate natural adversarial text. By applying it to two fundamental natural language tasks, text classification and textual entailment, we successfully attacked three target models, including the powerful pre-trained BERT, and the widely used convolutional and recurrent neural networks. We demonstrate the advantages of this framework in three ways: (1) effective---it outperforms state-of-the-art attacks in terms of success rate and perturbation rate, (2) utility-preserving---it preserves semantic content and grammaticality, and remains correctly classified by humans, and (3) efficient---it generates adversarial text with computational complexity linear to the text length. *The code, pre-trained target models, and test examples are available at https://github.com/jind11/TextFooler.\n","- __BAEGarg2019-BAE (BAE: BERT-Based Adversarial Examples)__ <br>\n","BAE, a black box attack for generating adversarial examples using contextual perturbations from a BERT masked language model. BAE replaces and inserts tokens in the original text by masking a portion of the text and leveraging the BERT-MLM to generate alternatives for the masked tokens. Through automatic and human evaluations, we show that BAE performs a stronger attack, in addition to generating adversarial examples with improved grammaticality and semantic coherence as compared to prior work.\n","- __BERTAttackLi2020 - BERT-ATTACK: Adversarial Attack Against BERT Using BERT.__ <br>\n","we propose \\textbf{BERT-Attack}, a high-quality and effective method to generate adversarial samples using pre-trained masked language models exemplified by BERT. We turn BERT against its fine-tuned models and other deep neural models for downstream tasks. Our method successfully misleads the target models to predict incorrectly, outperforming state-of-the-art attack strategies in both success rate and perturb percentage, while the generated adversarial samples are fluent and semantically preserved. Also, the cost of calculation is low, thus possible for large-scale generations.\n","- __TextBugger: Generating Adversarial Text Against Real-world Applications.__ <br>\n","Deep Learning-based Text Understanding (DLTU) is the backbone technique behind various applications, including question answering, machine translation, and text classification. Despite its tremendous popularity, the security vulnerabilities of DLTU are still largely unknown, which is highly concerning given its increasing use in security-sensitive applications such as sentiment analysis and toxic content detection. In this paper, we show that DLTU is inherently vulnerable to adversarial text attacks, in which maliciously crafted texts trigger target DLTU systems and services to misbehave. Specifically, we present TextBugger, a general attack framework for generating adversarial texts. In contrast to prior works, TextBugger differs in significant ways: (i) effective -- it outperforms state-of-the-art attacks in terms of attack success rate; (ii) evasive -- it preserves the utility of benign text, with 94.9\\% of the adversarial text correctly recognized by human readers; and (iii) efficient -- it generates adversarial text with computational complexity sub-linear to the text length. We empirically evaluate TextBugger on a set of real-world DLTU systems and services used for sentiment analysis and toxic content detection, demonstrating its effectiveness, evasiveness, and efficiency. For instance, TextBugger achieves 100\\% success rate on the IMDB dataset based on Amazon AWS Comprehend within 4.61 seconds and preserves 97\\% semantic similarity. We further discuss possible defense mechanisms to mitigate such attack and the adversary's potential countermeasures, which leads to promising directions for further research.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PrbS2Z-H3sQs","executionInfo":{"status":"ok","timestamp":1627953626898,"user_tz":-120,"elapsed":405,"user":{"displayName":"Bhupender Kumar Saini","photoUrl":"","userId":"04265374379702190944"}},"outputId":"29726ae4-42a9-44a3-b23d-5511adffcf4a"},"source":["'''\n","Some of the attack recipe provided by textattack is not working with lengthy article. So, \n","I am filtering the with the length. May be in future I will remove it.\n","'''\n","df_test['len']=df_test.apply(lambda row: len(row[feature_col.value].split()),axis=1)\n","df_test_for_attack= df_test[(df_test['len']>0) & (df_test['len']<20)][[feature_col.value,target_col.value]].dropna().reset_index(drop=True)\n","df_test_for_attack=df_test_for_attack.sample(frac=1).reset_index(drop=True)\n","print('Length of dataset', len(df_test_for_attack))\n","\n","\n","#creating dataset for the attacking\n","dataset_for_attack=list(df_test_for_attack.itertuples(index=False, name=None))\n","dataset_for_attack = textattack.datasets.Dataset(dataset_for_attack)\n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Length of dataset 790\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"z72SLjrSm-l1"},"source":["### BERT model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"NeDTUCe_hFvr","executionInfo":{"status":"error","timestamp":1627956192807,"user_tz":-120,"elapsed":2554697,"user":{"displayName":"Bhupender Kumar Saini","photoUrl":"","userId":"04265374379702190944"}},"outputId":"cb430ce4-97c1-4464-d4f0-0d37b873b458"},"source":["bert= bert_model(pretrained_weights.value,max_len.value,learning_rate.value) \n","bert.load_weights(bert_to_attack)\n","\n","attack_model(bert, \n","             dataset_for_attack,\n","             pretrained_weights.value,\n","             max_len.value,\n","             model_name.value,\n","             attack_recipe=attack_recipe.value,\n","             query_budget= query_budget.value,\n","             num_examples=num_examples.value )"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Model selected: distilbert-base-uncased\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_layer_norm', 'activation_13', 'vocab_projector']\n","- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","textattack: Unknown if model of class <class 'tensorflow.python.keras.engine.functional.Functional'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n","textattack: Logging to CSV at path Result/BERTAttackLi2020/DistillBERT_nexp500_qb200_2021-08-03_01:20.csv\n","\n","  0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Attack(\n","  (search_method): GreedyWordSwapWIR(\n","    (wir_method):  unk\n","  )\n","  (goal_function):  UntargetedClassification\n","  (transformation):  WordSwapMaskedLM(\n","    (method):  bert-attack\n","    (masked_lm_name):  BertForMaskedLM\n","    (max_length):  512\n","    (max_candidates):  48\n","    (min_confidence):  0.0005\n","  )\n","  (constraints): \n","    (0): MaxWordsPerturbed(\n","        (max_percent):  0.4\n","        (compare_against_original):  True\n","      )\n","    (1): UniversalSentenceEncoder(\n","        (metric):  cosine\n","        (threshold):  0.2\n","        (window_size):  inf\n","        (skip_text_shorter_than_window):  False\n","        (compare_against_original):  True\n","      )\n","    (2): RepeatModification\n","    (3): StopwordModification\n","  (is_black_box):  True\n",") \n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 1/500 [00:03<33:00,  3.97s/it]\u001b[A\n","[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:   0%|          | 1/500 [00:03<33:15,  4.00s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["--------------------------------------------- Result 1 ---------------------------------------------\n","\u001b[92m1 (73%)\u001b[0m --> \u001b[91m0 (58%)\u001b[0m\n","\n","\u001b[92msay\u001b[0m the coronavirus ha a recovery rate in texas\n","\n","\u001b[91mknow\u001b[0m the coronavirus ha a recovery rate in texas\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:   0%|          | 2/500 [00:06<25:01,  3.01s/it]\u001b[A\n","[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:   0%|          | 2/500 [00:06<25:07,  3.03s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["--------------------------------------------- Result 2 ---------------------------------------------\n","\u001b[91m0 (72%)\u001b[0m --> \u001b[92m1 (51%)\u001b[0m\n","\n","\u001b[91mcoronavirus\u001b[0m slovenia and guadeloupe added to \u001b[91menglands\u001b[0m quarantine list but thailand and singapore removed\n","\n","\u001b[92msin\u001b[0m slovenia and guadeloupe added to \u001b[92menglandlead\u001b[0m quarantine list but thailand and singapore removed\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:   1%|          | 3/500 [00:06<18:00,  2.17s/it]\u001b[A\n","[Succeeded / Failed / Skipped / Total] 3 / 0 / 0 / 3:   1%|          | 3/500 [00:06<18:04,  2.18s/it]\u001b[A\n","[Succeeded / Failed / Skipped / Total] 3 / 0 / 0 / 3:   1%|          | 4/500 [00:06<13:43,  1.66s/it]\u001b[A\n","[Succeeded / Failed / Skipped / Total] 3 / 0 / 1 / 4:   1%|          | 4/500 [00:06<13:46,  1.67s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["--------------------------------------------- Result 3 ---------------------------------------------\n","\u001b[92m1 (73%)\u001b[0m --> \u001b[91m0 (54%)\u001b[0m\n","\n","the \u001b[92mcdc\u001b[0m recommends that only people with covid symptom should wear mask\n","\n","the \u001b[91mthis\u001b[0m recommends that only people with covid symptom should wear mask\n","\n","\n","--------------------------------------------- Result 4 ---------------------------------------------\n","\u001b[91m0 (73%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n","\n","riding in the time of coronavirus how single people are handling thing\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","[Succeeded / Failed / Skipped / Total] 3 / 0 / 1 / 4:   1%|          | 5/500 [00:07<12:11,  1.48s/it]\u001b[A\n","[Succeeded / Failed / Skipped / Total] 4 / 0 / 1 / 5:   1%|          | 5/500 [00:07<12:13,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["--------------------------------------------- Result 5 ---------------------------------------------\n","\u001b[91m0 (73%)\u001b[0m --> \u001b[92m1 (61%)\u001b[0m\n","\n","death continue falling the \u001b[91mday\u001b[0m \u001b[91maverage\u001b[0m just edged under\n","\n","death continue falling the \u001b[92mmean\u001b[0m \u001b[92msun\u001b[0m just edged under\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","[Succeeded / Failed / Skipped / Total] 4 / 0 / 1 / 5:   1%|          | 6/500 [00:08<11:09,  1.36s/it]\u001b[A\n","[Succeeded / Failed / Skipped / Total] 5 / 0 / 1 / 6:   1%|          | 6/500 [00:08<11:11,  1.36s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["--------------------------------------------- Result 6 ---------------------------------------------\n","\u001b[92m1 (73%)\u001b[0m --> \u001b[91m0 (61%)\u001b[0m\n","\n","\u001b[92mindian\u001b[0m \u001b[92mgovernment\u001b[0m snooping message over social medium and all social medium platform will be monitored for covid message\n","\n","\u001b[91mincluding\u001b[0m \u001b[91mgovt\u001b[0m snooping message over social medium and all social medium platform will be monitored for covid message\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","[Succeeded / Failed / Skipped / Total] 5 / 0 / 1 / 6:   1%|▏         | 7/500 [00:58<1:08:42,  8.36s/it]\u001b[A\n","[Succeeded / Failed / Skipped / Total] 6 / 0 / 1 / 7:   1%|▏         | 7/500 [00:58<1:08:43,  8.36s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["--------------------------------------------- Result 7 ---------------------------------------------\n","\u001b[91m0 (72%)\u001b[0m --> \u001b[92m1 (59%)\u001b[0m\n","\n","\u001b[91mlabour\u001b[0m leader sir keir starmer is \u001b[91mselfisolating\u001b[0m after a member of his household displayed possible coronavirus symptom\n","\n","\u001b[92mthe\u001b[0m leader sir keir starmer is \u001b[92mselfisot\u001b[0m after a member of his household displayed possible coronavirus symptom\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","[Succeeded / Failed / Skipped / Total] 6 / 0 / 1 / 7:   2%|▏         | 8/500 [00:59<1:00:31,  7.38s/it]\u001b[A\n","[Succeeded / Failed / Skipped / Total] 7 / 0 / 1 / 8:   2%|▏         | 8/500 [00:59<1:00:32,  7.38s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["--------------------------------------------- Result 8 ---------------------------------------------\n","\u001b[92m1 (73%)\u001b[0m --> \u001b[91m0 (61%)\u001b[0m\n","\n","hair weave and lace front manufactured in \u001b[92mchina\u001b[0m may contain the coronavirus\n","\n","hair weave and lace front manufactured in \u001b[91mshu\u001b[0m may contain the coronavirus\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","[Succeeded / Failed / Skipped / Total] 7 / 0 / 1 / 8:   2%|▏         | 9/500 [00:59<54:20,  6.64s/it]  \u001b[A\n","[Succeeded / Failed / Skipped / Total] 8 / 0 / 1 / 9:   2%|▏         | 9/500 [00:59<54:21,  6.64s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["--------------------------------------------- Result 9 ---------------------------------------------\n","\u001b[92m1 (73%)\u001b[0m --> \u001b[91m0 (53%)\u001b[0m\n","\n","when \u001b[92mshri\u001b[0m amitshah became covid positive shantidoots were organizing \u001b[92mfuneral\u001b[0m\n","\n","when \u001b[91minto\u001b[0m amitshah became covid positive shantidoots were organizing \u001b[91muntil\u001b[0m\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","[Succeeded / Failed / Skipped / Total] 8 / 0 / 1 / 9:   2%|▏         | 10/500 [01:01<49:56,  6.11s/it]\u001b[A\n","[Succeeded / Failed / Skipped / Total] 9 / 0 / 1 / 10:   2%|▏         | 10/500 [01:01<49:56,  6.12s/it]\u001b[A\n","[Succeeded / Failed / Skipped / Total] 9 / 0 / 1 / 10:   2%|▏         | 11/500 [01:01<45:23,  5.57s/it]\u001b[A\n","[Succeeded / Failed / Skipped / Total] 9 / 0 / 2 / 11:   2%|▏         | 11/500 [01:01<45:24,  5.57s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["--------------------------------------------- Result 10 ---------------------------------------------\n","\u001b[92m1 (73%)\u001b[0m --> \u001b[91m0 (64%)\u001b[0m\n","\n","these \u001b[92mpicture\u001b[0m are of dr v k srinivas of \u001b[92mbharat\u001b[0m biotech taking the first second dos of corona vaccine\n","\n","these \u001b[91mfeatures\u001b[0m are of dr v k srinivas of \u001b[91mbforest\u001b[0m biotech taking the first second dos of corona vaccine\n","\n","\n","--------------------------------------------- Result 11 ---------------------------------------------\n","\u001b[91m0 (54%)\u001b[0m --> \u001b[37m[SKIPPED]\u001b[0m\n","\n","july ha le death than july despite pandemic\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","[Succeeded / Failed / Skipped / Total] 9 / 0 / 2 / 11:   2%|▏         | 12/500 [01:01<42:00,  5.17s/it]\u001b[A\n","[Succeeded / Failed / Skipped / Total] 10 / 0 / 2 / 12:   2%|▏         | 12/500 [01:02<42:01,  5.17s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["--------------------------------------------- Result 12 ---------------------------------------------\n","\u001b[92m1 (73%)\u001b[0m --> \u001b[91m0 (68%)\u001b[0m\n","\n"," contact \u001b[92mtracing\u001b[0m apps have been \u001b[92msecretly\u001b[0m installed on every android phone  \n","\n"," contact \u001b[91mtrace\u001b[0m apps have been \u001b[91msince\u001b[0m installed on every android phone  \n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n","[Succeeded / Failed / Skipped / Total] 10 / 0 / 2 / 12:   3%|▎         | 13/500 [01:49<1:08:04,  8.39s/it]\u001b[A\n","[Succeeded / Failed / Skipped / Total] 11 / 0 / 2 / 13:   3%|▎         | 13/500 [01:49<1:08:05,  8.39s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["--------------------------------------------- Result 13 ---------------------------------------------\n","\u001b[92m1 (73%)\u001b[0m --> \u001b[91m0 (55%)\u001b[0m\n","\n","trump s \u001b[92mcovid\u001b[0m test came back positive for stupidity \u001b[92mdonaldtrump\u001b[0m whitehouse coronavirus c\n","\n","trump s \u001b[91mcox\u001b[0m test came back positive for stupidity \u001b[91mdonaldtrumthe\u001b[0m whitehouse coronavirus c\n","\n","\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-15d02a8b0f1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m              \u001b[0mattack_recipe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattack_recipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m              \u001b[0mquery_budget\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mquery_budget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m              num_examples=num_examples.value )\n\u001b[0m","\u001b[0;32m/content/drive/MyDrive/Master Thesis/Mean-Teacher-BERT-assessment/Attack_model/TextAttack.py\u001b[0m in \u001b[0;36mattack_model\u001b[0;34m(model, dataset_for_attack, pretrained_weights, max_len, model_name, attack_recipe, query_budget, num_examples)\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/GPU:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mattacker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttacker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_for_attack\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattack_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mattacker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textattack/attacker.py\u001b[0m in \u001b[0;36mattack_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attack_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textattack/attacker.py\u001b[0m in \u001b[0;36m_attack\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack_attrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textattack/attack.py\u001b[0m in \u001b[0;36mattack\u001b[0;34m(self, example, ground_truth_output)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSkippedAttackResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoal_function_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoal_function_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textattack/attack.py\u001b[0m in \u001b[0;36m_attack\u001b[0;34m(self, initial_result)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mMaximizedAttackResult\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \"\"\"\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mfinal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfinal_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoal_status\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGoalFunctionResultStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUCCEEDED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textattack/search_methods/search_method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, initial_result)\u001b[0m\n\u001b[1;32m     34\u001b[0m             )\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;31m# ensure that the number of queries for this GoalFunctionResult is up-to-date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_queries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoal_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textattack/search_methods/greedy_word_swap_wir.py\u001b[0m in \u001b[0;36mperform_search\u001b[0;34m(self, initial_result)\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0mcur_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacked_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0moriginal_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacked_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0mindices_to_modify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_order\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             )\n\u001b[1;32m    133\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textattack/attack.py\u001b[0m in \u001b[0;36mget_transformations\u001b[0;34m(self, current_text, original_text, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 transformed_texts = self._get_transformations_uncached(\n\u001b[0;32m--> 274\u001b[0;31m                     \u001b[0mcurrent_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m                 )\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textattack/attack.py\u001b[0m in \u001b[0;36m_get_transformations_uncached\u001b[0;34m(self, current_text, original_text, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mcurrent_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mpre_transformation_constraints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_transformation_constraints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         )\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textattack/transformations/transformation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, current_text, pre_transformation_constraints, indices_to_modify, shifted_idxs)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconstraint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpre_transformation_constraints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mindices_to_modify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_to_modify\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mtransformed_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_transformations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_to_modify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransformed_texts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack_attrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"last_transformation\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textattack/transformations/word_swaps/word_swap_masked_lm.py\u001b[0m in \u001b[0;36m_get_transformations\u001b[0;34m(self, current_text, indices_to_modify)\u001b[0m\n\u001b[1;32m    269\u001b[0m                     \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                     \u001b[0mid_preds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_preds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                     \u001b[0mmasked_lm_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasked_lm_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m                 )\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textattack/transformations/word_swaps/word_swap_masked_lm.py\u001b[0m in \u001b[0;36m_bert_attack_replacement_words\u001b[0;34m(self, current_text, index, id_preds, masked_lm_logits)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_lm_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ids_pos_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m                 \u001b[0mperplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                 word = \"\".join(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 962\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2468\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"2T_YPZT5nBw6"},"source":["### MTBERT model"]},{"cell_type":"code","metadata":{"id":"MQowRIA78W79","executionInfo":{"status":"aborted","timestamp":1627956192805,"user_tz":-120,"elapsed":6,"user":{"displayName":"Bhupender Kumar Saini","photoUrl":"","userId":"04265374379702190944"}}},"source":["bert_teacher= bert_model(pretrained_weights.value,max_len.value,learning_rate.value) \n","bert_teacher.load_weights(MTbert_to_attack)\n","\n","attack_model(bert_teacher, \n","             dataset_for_attack,\n","             pretrained_weights.value,\n","             max_len.value,\n","             'MT'+model_name.value,\n","             attack_recipe=attack_recipe.value,\n","             query_budget= query_budget.value,\n","             num_examples=num_examples.value )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qeftFUoeEHY4"},"source":[""],"execution_count":null,"outputs":[]}]}